# LOFAR IMAGING PIPELINE
# imager_bbz BBS (BlackBoard Selfcal) recipe
# Wouter Klijn
# klijn@astron.nl
# ------------------------------------------------------------------------------
from __future__ import with_statement
import sys
import collections
import os

from lofarpipe.support.remotecommand import RemoteCommandRecipeMixIn
from lofarpipe.support.baserecipe import BaseRecipe
from lofarpipe.support.group_data import load_data_map, store_data_map, validate_data_maps
import lofarpipe.support.lofaringredient as ingredient
from lofarpipe.support.remotecommand import ComputeJob

class imager_bbs(BaseRecipe, RemoteCommandRecipeMixIn):
    """
    imager_bbs master performs a bbs based on the supplied parset it is a shallow
    wrapper around bbs
    It validates that the input mapfiles are correct and then starts the node
    script
    
    **Arguments**
    """
    inputs = {
        'parset': ingredient.FileField(
            '-p', '--parset',
            help = "BBS configuration parset"
        ),
        'bbs_executable': ingredient.StringField(
            '--bbs-executable',
            help = "BBS standalone executable (bbs-reducer)"
        ),
        'instrument_mapfile': ingredient.FileField(
            '--instrument-mapfile',
            help = "Full path to the mapfile containing the names of the "
                 "instrument model files generated by the `parmdb` recipe"
        ),
        'sourcedb_mapfile': ingredient.FileField(
            '--sourcedb-mapfile',
            help = "Full path to the mapfile containing the names of the "
                 "sourcedbs generated by the `sourcedb` recipe"
        ),
        'id': ingredient.IntField(
            '--id',
            default = 0,
            help = "Optional integer id for distinguishing multiple runs"
        ),
        'mapfile': ingredient.StringField(
            '--mapfile',
            help = "Full path to the file containing the output data products"
        ),
    }

    outputs = {
        'mapfile': ingredient.FileField(
            help = "Full path to a mapfile describing the processed data"
        )
    }

    def go(self):
        super(imager_bbs, self).go()
        self.logger.info("Starting imager_bbs run")

        # Load the data
        ms_map = load_data_map(self.inputs['args'][0])
        parmdb_map = load_data_map(self.inputs['instrument_mapfile'])
        sourcedb_map = load_data_map(self.inputs['sourcedb_mapfile'])

        #Check if the input has equal length and on the same nodes
        if not validate_data_maps(ms_map, parmdb_map, sourcedb_map):
            self.logger.error("The combination of mapfiles failed validation:")
            self.logger.error(ms_map)
            self.logger.error(parmdb_map)
            self.logger.error(sourcedb_map)
            return 1

        # Create the jobs
        jobs = []
        outnames = collections.defaultdict(list)
        node_command = " python %s" % (self.__file__.replace("master", "nodes"))

        for (ms, parmdb, sourcedb) in zip(ms_map, parmdb_map, sourcedb_map):
            #host is same for each entry (validate_data_maps)
            (host, ms_list) = ms

            # Write data maps to mapfiles: The (node, data) pairs are inserted
            # into an array to allow writing of the mapfiles using the default 
            # functions
            map_dir = os.path.join(
                        self.config.get("layout", "job_directory"), "mapfiles")
            run_id = str(self.inputs.get("id"))
            ms_list_path = os.path.join(map_dir, host + "_ms_" + run_id + ".map")
            store_data_map(ms_list_path, [ms])
            self.logger.debug(
                "Wrote mapfile with ms: {0}".format(ms_list_path))
            parmdb_list_path = os.path.join(map_dir, host + "_parmdb_" + run_id + ".map")
            store_data_map(parmdb_list_path, [parmdb])
            self.logger.debug(
                "Wrote mapfile with parmdb: {0}".format(parmdb_list_path))
            sourcedb_list_path = os.path.join(map_dir, host + "_sky_" + run_id + ".map")
            store_data_map(sourcedb_list_path, [sourcedb])
            self.logger.debug(
                "Wrote mapfile with sourcedbs: {0}".format(parmdb_list_path))

            outnames[host].extend(ms_list)

            arguments = [self.inputs['bbs_executable'],
                         self.inputs['parset'],
                         ms_list_path, parmdb_list_path, sourcedb_list_path]
            jobs.append(ComputeJob(host, node_command, arguments))

        # start and wait till all are finished
        self._schedule_jobs(jobs)

        if self.error.isSet():   #if one of the nodes failed
            self.logger.error("One of the nodes failed while performing"
                              "a BBS run. Aborting")
            return 1

        # return the output: The measurement set that are calibrated:
        # calibrated data is placed in the ms sets
        store_data_map(self.inputs['mapfile'], ms_map)
        self.logger.debug("Wrote datamap with calibrated data: {0}".format(
                                      self.inputs['mapfile']))
        self.outputs['mapfile'] = self.inputs['mapfile']
        return 0


if __name__ == '__main__':
    sys.exit(imager_bbs().main())
