        Installation instructions for PSS4
        

1. Prerequisites 

  Current version numbers given; not guaranteed to work with earlier versions.
  (Most of this can be found on lofar9/10 under /usr/local/src.)

  Basic build:

    * Access to cvs.astron.nl. Read the LOFAR Build System document!

    * gcc-3.3.2 (not 3.4 yet!)

    * GNU toolset: automake 1.6.3, autoconf 2.53, libtool 1.5.2

    * A recent (post-library split) build of AIPS++

    * Blitz++ 0.6

    * log4cplus-1.0 

  Python meqbrowser (build/install in this order!)

    * Qt 3.3.2

    * Python 2.3.4

    * numarray-0.9 (Python package)

    * sip-4.0.1 (see http://www.riverbankcomputing.co.uk/pyqt/index.php)

    * PyQt-3.12

  For Tony's meqbrowser visualization plug-ins:

    * Boost-jam 3.1.10

    * Boost 1.31.0

    * Hippodraw 1.12
  
2. Installation notes for external packages

  Generally, we build everything from source, and keep it under /usr/local. Look
  on lofar9/10 for an example layout. Configuartion/build notes on specific
  packages:

  2.1. gcc-3.3.2 

  We configure it as follows:

  configure --prefix=/usr/local/gcc-3.3.2 
            --enable-threads=posix 
            --enable-version-specific-runtime-libs 
            --enable-languages=c,c++,f77
  make bootstrap && make install

  You may want to then set CC=/usr/local/gcc-3.3.2/bin/gcc and 
  CXX=/usr/local/gcc-3.3.2/bin/g++ in your environment, so that everything else
  is built with this compiler (this does matter for some of the packages!)

  2.2 GNU tools

  Configure with --prefix=/usr/local, and make sure that /usr/local/bin is first
  in your $PATH. Or just upgrade whatever version is in /usr.

  2.3. AIPS++ 

  As long as you've sourced aipsinit (i.e. your $AIPSPATH is set correctly),
  the LOFAR build system will figure everything else out.

  2.4. Blitz++

  ./configure --prefix=/usr/local/blitz/gnu3
  make && make install

  Blitz is somewhat sensitive to compilers, hence you need to keep different
  version if you use other compilers, the strange install path (the LOFAR build
  system will look for it there). Build it with gcc-3.3.2!

  2.5. log4cplus-1.0 

  ./configure --prefix=/usr/local
  make && make install

  2.6. Qt 3.3.2

  ./configure -thread -enable-opengl -prefix /usr/local/qt-3.3.2
  make && make install

  2.7 Python 2.3.4

  ./configure --prefix=/usr/local
  make && make install

  After make install, set /usr/bin/python to link to /usr/local/bin/python2.3,
  and /usr/include/python2.3 to /usr/local/include/python2.3.

  2.8. numarray-0.9 (Python package)

  See README. Run "python setup.py install" using the python built above, it
  should figure out the rest.

  2.9. sip

  See README. You'll probably need to run:
  
    configure.py -l qt-mt CXX="$CXX" CC="$CC"
    make && make install
    
  2.10. PyQT

  See README. You'll probably need to run:
  
    python configure.py 
    make && make install
    
  2.11. Boost-jam, Boost 
    
    See specific installation instructions for these packages. Install to
    /usr/local, and don't forget to enable boost-python.

  2.11. Hippodraw 

  ./configure --prefix=/usr/local --enable-sipbuild --enable-numarraybuild
  --with-boost-include=/usr/local/boost-1.31.0/include/boost-1_31
  --with-boost-lib=/usr/local/boost-1.31.0/lib/ --with-Qt-dir=/usr/local/qt-3.3.2
  --with-Qt-lib=qt-mt
  
  ...was the easy part. As of 1.12.2, they still have a broken configure script,
  so you now need to set up some stuff by hand. Go into the ./sip subdirectory
  of the Hippo source tree, and look at the INSTALL file there. Specifically,
  you need to make sure that sip/Makefile contains:

      SIP = /usr/local/bin/sip
      PYQT_SRCS = -I /usr/local/share/sip -I /usr/local/share/sip/qtcanvas
      
  and finally, find the lines that look like:

      sipsihippocmodule.h : $(SIP_SRCS) 
	      @echo creating built sources
	      $(SIP) -e -g -c . $(PYQT_SRCS) -I $(top_srcdir)/sip  \
	      -t Qt_3_3_0 -t WS_X11 $(top_srcdir)/sip/sihippo.sip
  
  and make sure it says "Qt_3_3_0" for Qt-3.3.x (better check versions.sip
  too, just like the INSTALL file in sip instructs you).
  
  Now, back in the base of the Hippo source tree:
  make && make install

3. Checking out and building PSS4 per se

  Assuming you have $CVSROOT set properly:

    :pserver:USERNAME@cvs.astron.nl:/cvs/cvsroot

  1. Start with 

    $ cvs login 
  # (persist until it logs you in)
    $ cvs co LOFAR/autoconf_share
    $ cvs up LOFAR/bootstrap
    $ cvs co LOFAR/LCS/Common
    $ cvs co LOFAR/DMI
    $ cvs co LOFAR/CEP/CPA
    # (the last one checks out a bunch of extra stuff under CEP/CPA that you
    # you don't really need. Delete later at your leisure. Only the following 
    # CEP/CPA packages are required for PSS4:
    #   OCTOPUSSY OCTOGlish OCTOPython GlishUtil VisCube AppAgent PSS4 PyApps

  2. Create the file LOFAR/lofarconf.in.private. This is just a list of packages
    to build, one per line (the default version, lofarconf.in, build the wrong 
    things). Use the following version:
    -------
       LCS/Common
       DMI
       CEP/CPA/OCTOPUSSY
       CEP/CPA/OCTOPython
       CEP/CPA/GlishUtil
       CEP/CPA/OCTOGlish
       CEP/CPA/VisCube
       CEP/CPA/AppAgent
       CEP/CPA/PSS4
       CEP/CPA/OCTOPython
       CEP/CPA/PyApps
    -------

  3. Create a variants file for your machine. Use variants.lofar10 as a 
    starting point.

    $ cd LOFAR/autoconf_share
    # this is assuming you're not on lofar10 to begin with.
    $ cp variants.lofar10 variants.YOUR_HOST_NAME

    Now check the variants file to make sure the compiler specification (CXX),
    Qt and aips++ paths all match your system. (Have no fear, if they don't, 
    you'll learn about it soon enough anyway).

    Note the use of "CXX=ccache\ /path/to/g++" in the file. This assumes you
    have ccache installed (and you should, it makes rebuilds a helluva lot 
    faster.) If you don't, just give the direct path to the compiler instead.

  3. Bootstrap the build environment, create build directory, configure:

    $ cd ~/LOFAR
    $ ./bootstrap
  # (watch messages go by...)
    $ mkdir -p build/gnu3_debug
    $ cd build/gnu3_debug
    $ ../../lofarconf
  # (watch messages go by...)
    $

  4. Now, an evil but necessary kludge until I can get automake to submit:

    $ cd ~/LOFAR/CEP/CPA/OCTOPython/build/gnu3_debug/src
    $ ln -s octopython.la liboctopython.la

    (If you skip this step, PyApps will complain about a missing 
    liboctopython.la during the build.)

  5. Build!

    $ cd ~/LOFAR/build/gnu3_debug
    $ make 
  # (Go out to lunch)
    $

  5a. On lofar9/10, you may harness the awesome power of distcc and clustering, 
  to build at relativistic speeds on 20+ CPUs:

    $ mkdir ~/.distcc
  # copy over my distcc hosts file:
    $ cp ~oms/.distcc/hosts ~/.distcc
    $ export CCACHE_PREFIX=distcc    # this assumes bash, tcsh use setenv
    $ make -j40 
  # and hope it works...

  6. Installing the software.

    Assuming make was successful:

    $ cd ~/LOFAR/build/gnu3_debug
    $ make install

    This copies the built software and scripts into ~/LOFAR/installed/gnu3_debug.
    Handy for doing "snapshot"-style installs. 

  6a. Symlinking instead of installing

    A handy alternative is to set up a tree of symlinks directly into the
    source/build tree. Then, you never need to install, only edit/rebuild. I 
    recommend this approach if you're editing scripts, as it saves a lot of
    useless installs. 

    For an example symlink tree, see lofar10:/home/oms/LOFAR/installed/symlinked.
    You should be able to just copy my tree (since I use relative symlinks) and
    have everything work:

    $ slogin lofar10
    # (login)
    $ cd /home/oms/LOFAR/installed
    $ tar cvf ~/symlinks.tar symlinked.tar
    # (move the .tar file to your machine, and untar under your LOFAR/installed)

    Alternatively, you can copy them over directly, if you have access to my
    home directory locally. E.g., working on lofar9, you could do:

    $ cd ~/LOFAR/installed
    $ cp -a /net/lofar10/home/oms/LOFAR/installed/symlinked .

  7. Setting up include paths

    For Python, you need to set the $PYTHONPATH environment variable to

        $HOME/LOFAR/installed/current/libexec/python

    For Glish, just copy over my .glishrc from lofar10. Or add the following to
    yours:

    #####
    system.path.include := [system.path.include,
      spaste(environ.HOME,'/LOFAR/installed/current/libexec/glish') ];

    lofar_software := [=];
    lofar_software.basepath := spaste(environ.HOME,'/LOFAR/installed/current');

    lofar_software.print_versions := T;

    lofar_software.gsm := [=];
    lofar_software.gsm.default_gsm_table := spaste(lofar_software.basepath,'/share/GSM/gsm.tab')

    lofar_software.meq := [=];
    lofar_software.meq.servers := [ './meqserver',spaste(lofar_software.basepath,'/bin/meqserver
    ####

    Note that this assumes that scripts and binaries may be found under
    ~/LOFAR/installed/current. 'current' should be set up as a symlink to
    whatever installation variant you actually want to use, i.e.,
    LOFAR/installed/gnu3_debug, or LOFAR/installed/symlinked.

  8. Some "simple" test trees

    To start the MEQ browser, run 
    LOFAR/installed/current/libexec/python/meqbrowser.py
    (or LOFAR/CEP/CPA/PyApps/src/meqbrowser.py, whichever's hanbier)

    In theory, you can just run leave the browser running permanently, as it
    connects/disconnects to the kernel automatically.

    To run a very simple test tree, go to 

    $ cd ~/LOFAR/CEP/CPA/PSS4/MeqServer/build/gnu3_debug
    $ glish -l ../../test/solver_test.g
    # and then at the glish prompt:
    - solver_test(0)
    # watch sparks fly, and use the browser to examine the tree
    # (if you don't see a tree, try clicking the refresh button at the top of the
    # tree list).

  8a. When things go wrong(TM)

    The kernel is run in a process called 'meqserver'. This process wil usually
    exit when you exit your glish session, but for reasons that are not yet 
    entirely clear, it may sometimes stay running in the background. Then, next
    time 'round you may end up with two running meqservers, at which point
    things get a little confusing for the browser. Someday I will resolve this
    cleanly, but in the meantime,

    $ killall -9 meqserver

    is a useful incantation to know.

  9. meqsolve.g

    Meqsolver.g solves for two sources in a Haystack simulated data set. To run
    meqsolve.g, you need to get a test measurement set. Get one here:

    lofar10:/home/oms/data-nobackup/haystack-ms/new_1_1/0128_vis_ninterp.MS

    and copy it some place you won't lose it... Now, set up a few more symlinks:

    $ cd ~/LOFAR/CEP/CPA/PSS4/MeqServer/build/gnu3_debug
    $ ln -s ../../test/*.g .
    $ ln -s src/meqserver .
    $ ln -s path/to/your/copy/of/test/measurement/set test.ms

    Now, you may run meqsolve.g. The '-filluvw' argument makes it populate the
    UVW tables first, you only need to give it _the very first time you use a
    particular MS_. It won't break things afterwards, but it's slow and useless
    to repeat the process.

    $ glish -l meqsolve.g -filluvw

    Everything else is controlled by editing meqsolve.g itself...
    
  
