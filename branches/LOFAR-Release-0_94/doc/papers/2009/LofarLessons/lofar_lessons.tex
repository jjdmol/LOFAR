\documentclass[article]{sig-alternate}

\usepackage{a4wide, mathptm, cite, graphicx, eurosym, subfigure, listings}

\begin{document}

\title{Lessons Learnt from Building the LOFAR Software Correlator}

\author{John W. Romein \\[3mm]
Stichting ASTRON (Netherlands Foundation for Research in Astronomy) \\
Dwingeloo, The Netherlands
}

\date{}

\maketitle


\begin{abstract}
This paper summarizes the lessons learnt from building the LOFAR software
correlator.
We should learn from them, and not make the same mistakes when building the
SKA or other telescopes.
\end{abstract}



\section{Introduction}

The LOFAR telescope is a big success.
The LOFAR software works very well.
However, this maturing process was a process of trial and error.
In this document, we list the things we learnt by doing something wrong.


\section{Hardware choice}

A six-rack IBM Blue Gene/L supercomputer was acquired to correlate all LOFAR
data, four of which were reserved for normal use (the others would be available
for special-purpose observations that require more processing power).
The choice for building a software correlator on a supercomputer was not bad:
the desire for multiple processing pipelines demand a flexible solution.
However, the choice for a Blue Gene/L had some drawbacks.

First, the timing was bad: the machine was installed during the spring of 2005.
However, until 2009, there were so few prototype LOFAR stations available
that no more than 2\% of its processing power had ever been used.
Second, the choice for a new type of supercomputer had as consequence that
the system software was far from mature: essential functionality was missing,
and during the first one and a half year, the system software was unstable
and external communication was slow.

Another thing that was not realized sufficiently is that hardware ages quickly:
the Blue Gene/L was replaced unexpectedly soon (in the summer of 2008),
by a Blue Gene/P.
The system had to be replaced: the vendor would not support the system
indefinitely.
The replacement lead to an additional software development effort.
All in all, the advantages of the replacement prevailed: both the hardware and
the system software of the second generation Blue Gene were significant
improvements with respect to the first generation.

In retrospect, it would have been better to first have a small Blue Gene/L
system to develop the correlator software and to correlate the limited
amount of data from the prototype stations, and to install more correlator
hardware on demand.


\section{Design errors}

The LOFAR system software was designed and described in an early version
of the Central Processing Design Document~\cite{X}.
The design was changed a couple of times in the course of the LOFAR development,
sometimes for practical reasons, sometimes to repair design errors.

One of the biggest design errors was the design of a feedback loop in the
processing pipeline, in combination with large buffers in the forward part
of the processing pipeline.







\subsection{Control}

All LOFAR applications are under control of a ``master program'', called
\emph{Monitor And Control\/} (MAC).
MAC provides the applications with observation characteristics by means of
a file, called a \emph{Parameter Set}.
This file has a very simple format: it contains lines with key--value pairs,
like \texttt{OLAP.nrBitsPerSample = 16}.
The value can be a string, integer value, floating point value, boolean
value or list of the aforementioned types.

We found that this format is too restrictive, since specifying structured
values is cumbersome.
For example, XXX
Worse, we also found that it is too late to change the format, since it
is used everywhere in the code.




\subsection{CEPframe}

Probably the biggest mistake was CEPframe~\cite{XXX}.
CEPframe was designed as a framework on top of which streaming data
applications could be built.
Although we had a working application built on top of CEPframe, we eventually
abandoned CEPframe, and the application became faster, simpler, and more
robust.

\emph{explain CEPframe}.

Below, we list the main reasons why CEPframe was a failure.

\begin{itemize}
\item
CEPframe was a bottom-up design, while the needs of the applications that
had to run on top of it, were not clear.
All kind of functionality was in the package, at least half of which was
never used.

\item
The user interface was 

\item
CEPframe used a multi-threaded design, but the Blue Gene/L did not support
threads.
To support the Blue Gene/L, all thread-dependend code had to be removed
from CEPframe.
The choice was made to create a second package, called tinyCEP, with reduced
functionality.
This was a bad choice, since the packages evolved differently, and code
had nothing to do with multi-threading, behaved differently in the two
packages.
A better choice would have been to put "\#define MULTI\_THREADING" directives
around thread-dependent code.

\item
CEPframe tried to unify all types of network libraries (like MPI and TCP)
and create one common interface on top of all protocols.
As a consequence, CEPframe provided only support for uni-directional
point-to-point communication (the only thing that \emph{all\/} underlying
protocols support), while the different network protocols thank
their right of existence to the fact that they are particularly good at
something.
This meant, that an application that runs on top of CEPframe has to implement
a complex collective operation like all-to-all (e.g., needed to transpose all
telescope data before they can be correlated) itself using single
point-to-point communication, even if CEPframe itself uses MPI, that natively
supports these collective operations.

\item
A major design failure was the fact that CEPframe could not reliably stop.
CEPframe internally spawned threads to provide asynchronous communications,
but these threads could not reliably stopped, because CEPframe did not know
when communication ends.
The application could tell CEPframe to stop, but if a communication thread
was already trying to receive data, a deadlock could occur.
This was a \emph{design\/} failure, because the race condition was already
in the design.

\item
CEPframe tried to make communication implicit, so that data that must be
received is magically there and data that must be sent disappears in an
equally magical way.
Explicit read() and write() calls are much easier to use.

\item
Some of the error conditions were reported by returning "false", others
by throwing an exception.
The user therefore has to both test explicitly for error codes and to catch
exceptions.

\item
CEPframe assumed that the format of the data sent over a channel was always
of the same type and the same size.
This turned out to be very restrictive.

\item
CEPframe introduced the concept of "rates", as different components may run
at different speeds.
For example, a producer component that supplies three consumer components
with data, may run at a rate that is three times higher than that of the
consumers.
The use of "rates" turned out to be horribly complex.
\end{itemize}



\section{Know your hardware}

To achieve good performance, one needs to know every little detail of the
hardware.
For example, to know which switch ports of a network switch are able to
switch at full speed (rather than using the backplane of the switch),
it may be necessary to unscrew the switch.

\section{Profile code}

For high-performance computing, it is necessary to profile the code and
understand where the time is spent.
The measured runtimes must be compared to what can be expected.
There are two important metrics: the number of operations performed (either
floating point or integer), and the amount of data transported (to whichever
cache level, main memory, disk, or network).
Typically, either one of these forms a bottleneck and determines the
computation time.

Consider the following example, where we use a machine that runs at 2.0~GHz
and can do 4~operations per cycle.
This machine can, at least in theory, do $8 \dot 10^9$ operations per second.
Now we measure a 


\section{Stability}

(Operating) system software that has a large user community is more stable
than Blue Gene system software that has only a few customers.


\bibliographystyle{plain}
\bibliography{lofar_lessons}



\end{document}
