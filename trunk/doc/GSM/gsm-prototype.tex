\documentclass[10pt]{article}

\oddsidemargin=-5mm
\oddsidemargin=-5mm
\textwidth=170mm

\title{GSM Concepts in PSS4}
\author{O.M. Smirnov}

\begin{document}
\sloppy

\newcommand{\url}[1]{{\tt #1}}

\maketitle

\section{Introduction}

\subsection{Preliminary thoughts and requirements}

According to JEN's {\em Prototype Selfcal System 4} \cite{PSS4}:

\begin{enumerate}

\item Stand-alone product

\item Subsets extracted into MEP database, and linked to MeqParms

\item Cat II prediction (Haystack simulator?)

\item Outline the development path to final size and functionality

\item Relation to NVO (interfaces!): Use the VOtable?

\item Put in all the 3C and 4C sources

\item Put in all the 3C84 sources for MAB

\item Continue adding to it with everything we do

\item Think about source representations (parameters, shapelets, pixons, images, etc.)

\item How to find subsets

\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Use cases}

In order to limit scope for PSS4, yet stay on the development path towards a
full-blown GSM, it is necessary to define a layered interface carefully. To do
this, we first need to consider the basic use cases:

  \subsection{A source maps to a set of MeqNodes?} 

For use with a MeqTree, a GSM source has to map to a collection of MeqNodes. In
the simplest case (i.e. vanilla point source), these are basic MeqParms: RA,
Dec, $I,Q,U,V$ fluxes. Any of the parameters may be variable in frequency
and/or time for some sources.

The parameters of more complex sources will end up being represented by little
sub-trees of their own (i.e., by a MeqExpr node with MeqParm children). For
example:

\begin{itemize}

\item Specific representations of time or frequency dependence, more
``physical'' than a polynomial. Representation via spectral index -- i.e. flux
as an exponential of frequency -- is a canonical example. The spectral index
would then be the actual MeqParm [solvable if so requested], and it needs to be
attached to a MeqExpr (the exponent) to compute flux.

\item Complex sources and Cat II sources bring in a whole zoo of concepts:
images, shapelets, etc. These will definitely require specialized MeqNodes
and/or MeqExprs. 

\end{itemize}

Note also that the GSM$\leftrightarrow$MeqNodes representation has to be
bidirectional. Once a source has been solved for, we may want to store the new
parameter values back into the GSM. But see below.

  \subsection{Automated source finding}

We need to implement automated source finding, at least in some primitive way. 
In terms of use cases, this implies being able to update the GSM with new
sources, from both the scripting layer, and perhaps C++. 

  \subsection{Inserting and updating sources}

Note that there should be a way to treat sources as temporary and local to a
specific solution or session. I.e., while the automatic source detection
algorithm may generate sources, we don't know if they're really there or not
until we have successfully solved for them. Similar considerations apply to
updated values of pre-existing GSM sources -- we may want to reuse the updated
values in another solution, discard them entirely, or really commit them to the
GSM.

The commit step needs to be explicit. It's OK if this step is done manually in
PSS4, but we should keep an eye on the possibility of some sort of automated
strategy. Should it be possible to assign several sets of parameter
values to one GSM object? In that case we could also consider assigning some
sort of ``confidence level'' to each set.

It seems we need to introduce the term {\em Local Sky Model} (LSM), that is,
the model being employed for a specific solution. This would be created as a
subset of the GSM (by doing a region search), but could then be updated with
auto-located sources (or sources explicitly added by the user), refined, etc.,
before [possibly though not necessarily] being merged back into the GSM. Rather
than a separate entity, the LSM could simply be a logical subset of the MEP
database, (MEPdb) but see below for a discussion.

  \subsection{Region search}
  
Extract the subset of the GSM (i.e. the LSM) for a given region of the sky,
within a given brightness range, etc. The query can and will incorporate other
criteria, but selection by coordinate is the biggest challenge. This operation
could be initiated from the scripting layer, or perhaps even from C++. Whether
the subset is extracted directly into data objects in the scripting language,
or first into the MEPdb (whatever that is) remains to be determined. See
discussion below.

  \subsection{Populating from existing catalogues}
  
The GSM will be pre-populated from existing data sets. This is generally a
``unique'', one-time -- or at least one-time-per-catalogue operation -- never
done on-the-fly.

  \subsection{NVO, VOTable and friends}

The NVO effort has produced the VOTable definition ({\em Proposed XML Format
for Astronomical Tables}, \cite{VOT}). This is directly relevant to the GSM in
several ways. Despite being out of PSS4's current scope, we should consider:

\begin{itemize}

\item If we want to play with NVO as a ``data provider'', then at some point we
need to be able to export subsets of the GSM in VOTable format. 

\item With a GSM$\rightarrow$VOTable converter, we could profit from outside
software packages, such as VOTable visualizers. There's definitely a trend in
developing this stuff around the world.

\item More and more catalogues are being made available online in VOTable form,
so a VOTable$\rightarrow$GSM importer could become important.

\end{itemize}

As a third possibility, I could imagine using the VOTable internally at some
point -- see discussion later on.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Design considerations}

\subsection{Layered interfaces}

Common sense \& design principles call for a layered interface, with one or
more layers between the database implementation  and the application. At the
bottom, we have the database engine itself (which, in the case of PSS4, is
simply an AIPS++ table). An [optional] intermediate layer could provide
query-lookup-read-update-insert functions, mapping primitive structures in the
database into compound objects such as ``a source'' or ``a collection of sources
for a region''. 

What is clear, is that at the application level, the interface has to
eventually present each source as a collection of MeqNode objects (or their
defrecs). If one needs to insert, e.g., the flux of a source into a tree, one 
don't usually want to know if it is a single MeqParm, or a complicated MeqExpr
-- hence the MeqNode treatment. Similar considerations apply to, e.g.,
visualization. 

My thinking at the moment that as far as PSS4 is concerned, we only need to
elaborate the Glish (i.e. scripting layer) interface -- the topmost layer --
and that no knowledge of the GSM is required on the C++ side. The underlying
functionality may be rapidly implemented in Glish alone, using AIPS++ Tables
for storage. This is probably sufficient for PSS4 purposes, represents very
little investment, and leaves us free to rip the guts out and replace them with
a real database later. 

\subsection{Do we have an LSM?}

The LSM does not necessarily need to exist as a separate entity. It could be
seen as simply a logical subset of the MEPdb that deals with sources. We
should, however, consider:

\begin{description}

\item[Lifecycle:] how long does an LSM exist, before being discarded and/or
merged back into the GSM? Certainly as long as the same observation is being
processed. However, I can see a user wanting to keep his LSM around longer,
perhaps to apply to a future observation of the same region.

\item[Portability:] will user John want to pass a copy of his LSM to user Jane?
How?

\item[Structure:] is it sufficient to consider the LSM as simple "flat" set of
parameters? If we allow complicated sources to be represented by sub-trees,
then I could imagine trying to solve for one of these sources and discovering
it is better modelled by a somewhat different tree. How do I represent this new
tree in the LSM? Clearly, the LSM needs to contain not only parameters, but
some structural relationships between them (actually, this applies to the GSM as
well).

\end{description}

These considerations seem to imply that the LSM is something more than a simple
subset of the MEPdb, so perhaps it should exist on its own at some level of the
implementation. Unless, that is, we decide that similar considerations apply to
the other MEPs, in which case the LSM concept can be merged into the more
general concept of a ``local'' MEPdb.

\subsection{VOTable}

There is nothing particularly ``magic'' about the VOTable format, apart from
the fact that it's becoming the international data exchange standard. Being
based on XML, it solves half of the I/O problem (that of reading/writing
structured data), since XML parsers are available for almost all conceivable
languages and platforms. The other half (making sense of the structure read,
and, conversely, writing sensible structure) has to be addressed separately.

VOTable allows for a very rich semantic structure, so it's certain that
whatever specific representation we choose for the GSM, any subset can be
easily mapped onto the format. Rich semantics are a double-edged sword though:
mapping the other way (VOTable$\rightarrow$GSM) can be a lot trickier, since
the  semantics of a VOTable from a different source may not be directly
compatible, so we can only hope to support some sensible subset (and write
custom conversion scripts otherwise). I propose we leave the issue at that for
PSS4.

What could be considered in more detail at this point are {\em unified content
descriptors} (developed at CDS Strasbourg, \cite{UCD1}, \cite{UCD2},
\cite{UCD3}). UCDs are a set of standard strings (labels) used in VOTable to
specify, essentially, what a datum means in astronomical or physical terms.
What UCDs provide is a concise, unified vocabulary for describing astronomical
data. Here's a sample (see full list at
http://vizier.u-strasbg.fr/viz-bin/UCDs):

{\small\begin{verbatim}
POL                              Polarization Related Quantities
...
  POL_STOKES                     Polarization Stokes Parameters
  POL_STOKES_I                   Stokes parameter I (total power)
  POL_STOKES_Q                   Stokes Parameter Q (absolute, or relative Q/I) [horizontal/vertical component]
  POL_STOKES_U                   Stokes Parameter U (absolute, or relative U/I) [diagonal component]
  POL_STOKES_V                   Stokes Parameter V (absolute, or relative V/I) [circular component]
POS                              Position Related Quantities
  POS_ANG                        Angular Position
    POS_ANG_DIST                 Angular Distance and related quantities
      POS_ANG_DIST_GENERAL       Angular Distance Or Separation
      POS_ANG_DIST_REL           Relative or Normalized Angular Distance
      POS_ANG_DIST_SQ            Quadratic Angular Distance
    POS_ANG_VEL                  Rate Of Position Change (drift motion, angular velocity)
...
  POS_EQ                         Equatorial Coordinates and related quantities
...
    POS_EQ_DEC                   Declination related quantities
      POS_EQ_DEC_3T              Third Term in Declination
      POS_EQ_DEC_MAIN            Declination
      POS_EQ_DEC_OFF             Declination or North-South Offset Difference
      POS_EQ_DEC_OTHER           Declination in Non-Standard Units or partial values
      POS_EQ_DEC_PRECESS         Precession Variation in Declination
      POS_EQ_DEC_REL             Relative Declination in a Special Scale
...
    POS_EQ_PREC                  Annual Precession Quantities
      POS_EQ_PREC_DEC            Annual Precession In Declination
      POS_EQ_PREC_RA             Precession Variation In RA
...
    POS_EQ_RA                    Right Ascension related quantities
      POS_EQ_RA_2T               Second Component in right Ascension
      POS_EQ_RA_3T               Third Term In Right Ascension
      POS_EQ_RA_CORR             Correction in Right Ascension
      POS_EQ_RA_MAIN             Right Ascension
      POS_EQ_RA_OFF              RA Offset or Residual In Right Ascension or along East-West
      POS_EQ_RA_OTHER            Right Ascension in Non-Standard Units or partial values
      POS_EQ_RA_REL              Relative Right Ascension in a Special Scale
\end{verbatim}}

Adopting the official UCD list as a source of [software] vocabulary (internally
in the GSM, and perhaps elsewhere in the system?) would generally simplify
interaction with the VOTable format. Besides, it would reduces confusion 
arising from different developers inventing their own identifiers for the same
things.

\subsubsection{Added value within the project?}

Does VOTable have some added value that can be exploited internally in the
project? One application to keep in mind is the GSM$\leftrightarrow$LSM
interface. Having a VOTable representation of the LSM would address some of the
concerns raised in the previous section. This is out of scope for PSS4 though.

\subsection{The Glish interface: sources and nodes}

NB: the following code examples are meant as just that -- examples, a departure
point for thinking about how things would work, so they shouldn't be taken too
literally. The interface we eventually implement may or may not be dissimilar.
Note also that the concepts used here are in no way unique to Glish; one could
easily imagine the same things done in Python. 

\subsubsection{Extracting an LSM}

To begin, we need to extract a subset of the GSM into the LSM. This is done
``once'', before commencing calibration of a data set.

\begin{verbatim}
include 'GSM.g'
  # Attaches to global GSM table. Optional tablename argument 
  # allows for testing with different versions of the GSM
GSM := attach_gsm([table_name]);   
  # Extract an LSM from the GSM.
  # This record specifies the query parameters. Using a record 
  # allows for maximum flexibility in the interface:
query := [ ra=ra,dec=dec,radius=radius,other optional fields ];
  # If the LSM exists as part of the MEPdb, then this will copy 
  # a subset of the GSM into the MEPdb. The MEPdb will perhaps be 
  # specified here in the call. Alternatively, the LSM could be 
  # extracted into a separate table of its own. In that case, the 
  # table name should be specified here.
lsm := GSM.extract_region(query,???);
\end{verbatim}

Once an LSM is extracted, we need to be able to reuse it in future
sessions without going back to the GSM:

\begin{verbatim}
  # if the LSM exists in its own table
lsm := attach_lsm(tablename)
  # ... or if the LSM lives inside the MEPdb
lsm := attach_lsm([mepdb]);
  # ... the mepdb argument specifies the MEPdb somehow.
\end{verbatim}

\subsubsection{Source lists}

Now that we have an LSM, we need to insert sources into MeqTrees. But first we
need a list of the sources in the LSM. It is useful to have this list already
pre-sorted in some order (e.g. by brightness -- if you want to peel in order of
brightness\footnote{There's a separate issue here, that a source does not 
necessarily have a single value for brightness -- in many cases it would
be a function of time and/or frequency. How would we sort on that? One answer is
to store a separate ``representative'' brightness -- an average or 
approximate value. You could then sort on this approximate value, and use
the full functional representation in calibration. This means that MeqNodes
would have to be responsible for calculating ``representative'' values.}). 
Also, perhaps we want only a subset of the sources?

\begin{verbatim} 
  # Extracts source list. Both arguments are optional: 
  # if no sort_by is given, returns unsorted list; 
  # if no subset is given, returns all the LSM sources.
  # The subset argument could be defined in the same way as the 
  # query argument in the GSM examples above. Note also the 
  # sneaky use of a UCD for sort_by:
sources := lsm.select_sources(sort_by='pol_stokes_i',subset=query); 
\end{verbatim}

What is {\tt sources}? Maybe just a list (i.e. vector, in Glish terms) of
names, or IDs, or in any case ``thingies'' we can later refer to a source by.
But I think it would be even more liberating (think ``Freedom layer'') if this
was actually a list of records (record of records, in Glish terms) with
additional information. E.g. each source record would be something like:

\begin{verbatim}
[ id=source_id,name=descriptive_name,
  ra=ra,dec=dec,pol_stokes_i=... ]
\end{verbatim}

The {\tt id} field is what we use to refer to a source later (i.e. index). From
a purely functional standpoint, this is sufficient, since you should also be
able to access the full source data via the id. However, the other fields
contain information about the source that could be very useful in making
calibration decisions later on (not to mention visualization etc.), so it's
handy to have it around from the start. How much or how little information do
we want to provide here? I suggest we make it all optional, that is, determined
by an optional argument to the {\tt select\_sources()} method:

\begin{verbatim}
sources := lsm.select_sources(sort_by='pol_stokes_i',
            subset=query,fields="name ra dec pol_stokes_i"); 
# fields argument is optional; the default value would be 
# something like the one shown here
\end{verbatim}

Note that in this form the method mirrors the {\tt SELECT} statement in SQL (as
in {\tt SELECT \em columns\tt\ FROM \em table\tt\  WHERE \em subset
criteria\tt\ SORT BY \em what}). So we're really dealing with an ubiquitous
concept here -- which probably shows that we're on the right track. 

\subsubsection{Hanging sources off trees}

At some point we get to constructing MeqTrees, where we'll probably loop over
sources (see \cite{PSS4}). 

\begin{verbatim}
for( i in 1:len(sources) )
{
  defrec := lsm.source_node(sources[i].id,'pol_stokes_i');
  node_index := MeqNode.define(name,defrec);
  ...
\end{verbatim}

The {\tt source\_node()} call here returns the {\em node definition record} for
the Stokes $I$ parameter of the given source. This is, of course, just the
defrec in JEN's terms \cite{PSS4}, with sufficient information to create the
node, so it can be passed directly to {\tt MeqNode.define()}. For example, if
$I$ is a single MeqParm with polynomial $t,f$ dependence, the defrec returned
would look something like:

\begin{verbatim}
[ class    = 'meqparm',
  id       = parm_id,
  name     = 'pol_stokes_i',
  domain   = ...,
  polc     = [array of polcs],
  ... ]
\end{verbatim} 

What if we want the MeqParm to be solvable? JEN \cite{PSS4} proposes a {\tt
MeqParm.set\_solvable()} method. Which is good, but we could also provide the
additional ability to mark a parm as solvable at creation time, by saying

\begin{verbatim}
defrec.solvable := T
\end{verbatim}

before passing the defrec to {\tt MeqParm.define()}. This is in keeping with
the concept of the defrec containing all the necessary information to create a
node.

Let's take it once step further. Suppose $I$ was represented in exponential
form, with a spectral index. What would its defrec look like? Without meaning
to go into detail about MeqExpr semantics -- what's shown here is just a
conceptual defrec -- how about:

\begin{verbatim}
[ class     = 'meqexpr',
  ...
  func      = 'exp',
  children  = [ 
    *1 = [ class    = 'meqparm',
           ...
           name     = 'spect_sp-index', # another UCD
           polc     = [...],
           solvable = T
           ... ],
    *2 = [ class    = 'meqparm',
           name     = 'freq',           
           polc     = [0,-1],
           solvable = F
           ... ] 
  ]
];
\end{verbatim}

The top-level defrec corresponds to a MeqExpr node implementing the $e^{xy}$
function. The {\tt children} field contains a list of child defrecs -- in this
case, $x$ is a MeqParm representing the [solvable] spectral index, and $y$ is
frequency term (the {\tt polc} array given corresponds to $-f$). Essentially,
we're representing a tiny tree here. The {\tt MeqParm.define()} method can then
recursively define the child nodes (to any level of nesting!), followed by the
top-level node.

{\bf A note on terminology.}{\em To avoid confusion, we need to clearly 
distinguish source parameters from atomic MeqParms. In the example here, Stokes
$I$ is a source parameter, which could be represented by a single MeqParm, or
by a compound expression -- subtree -- involving one or more atomic MeqParms
(themselves polynomials of $t,f$). In this document, I use {\bf source
parameter} to refer to things like RA, Dec, Stokes $I$, ..., and {\bf MeqParm} to
refer to their constituent MeqParm nodes.}

Note three emerging powerful concepts here:

\begin{itemize}
\item At the script level, when constructing a tree, one {\bf does not care} how
a source parameter is represented. It could be a single MeqParm, it could be a
subtree -- the code to insert this parameter at a given point in the
MeqTree remains exactly the same.

\item GSM sources can be represented to any level of complexity, by using
subtrees to represent their parameters.

\item You don't even need a GSM source! Suppose you want to add an extra source
to see if that improves calibration. No need to insert it into the LSM --  just
construct the appropriate defrecs in Glish, and insert them into your trees.
The C++ side of things (and trees in general) don't know or care whether the
sources come from the GSM, or have been added by the user on-the-fly. Once
you've determined that the source fits the data, then you can commit it to
the LSM.

The same goes for modifying a source parameter. A source not being fitted
properly, because $I$ seems to have a more complex $t,f$ dependence than that 
stored in the LSM? Modify it's defrec (perhaps setting up a more complex
subtree) before passing it to {\tt MeqParm.define()}, and if that works out,
you can commit the new representation back to the LSM. 
\end{itemize}

\subsubsection{Viewing and committing the results}

Once we've solved for source parameters, we want to (a) look at them, and more
importantly (b) commit them back to the LSM if the solution is good. At this
point, the information resides in MeqNodes on the C++ side. Using JEN's
mechanism \cite{PSS4}, you would do something like:

\begin{verbatim}
state_record := MeqNode.get_state(node_index,[recurse=-1,...]);
\end{verbatim}

...to obtain the state of a node together with all of its children ({\tt
recurse=-1}), down to the MeqParm leaves. (Of course we need to know the node
index first -- more on that below.) At this point, the state record contains
everything you need to know (provided the sufficient level of detail is
specified in the {\tt "..."} part of the call, somehow) about the source
parameter\footnote{During discussions with JEN, the concepts of a state record
and a defrec have been stealthily converging. A defrec is basically the
complete {\em initial} state record of a node.}, which is sufficient for
visualization, etc. 

When and how should this information be written back to the LSM? Someone,
somewhere has to say ``commit''. This is a control decision, and belongs on the
policy side of the policy barrier \cite{PSS4}, so it should be initiated in
Glish. A general solution would be a call like...

{\tt MeqNode.commit\_node(}{\em node\_index or indices}{\tt)}, with a recursion 
argument, to commit all MeqParms in the subtree rooted at this
node\footnote{Here's a good question: should this recursion be always
implicit?}. Note that this applies to all MEPs, not just source parameters.

Where would we get the {\tt node\_index} argument? A source has parameters, and
these become associated with MeqNodes (either single MeqParms or entire
subtrees). The mapping between a source parameter and its node is transient --
established only at run-time, when the tree is constructed. In the code
fragment above:

\begin{verbatim}
defrec := lsm.source_node(sources[i].id,'pol_stokes_i');
node_index := MeqNode.define(name,defrec);
\end{verbatim}

...something has to happen to associate {\tt node\_index} with the $I$
parameter of this source. Perhaps the {\tt lsm} object should be allowed to call
{\tt .define()} by itself, and put the resulting node index into the defrec?
An alternative suggestion is proposed below. This requires further discussion.

Another thing to consider is that the nodes associated with a source belong
together and should usually be committed as a unit. In database parlance, they
should be committed in a single transaction. If your program happens to crash
(for whatever reason) while the MeqParms are being stored, this leaves the
database in an unknown, possibly corrupt state (which values have been written?
which haven't?) It's even more dangerous if you're storing the subtree
representation (i.e. structural relationships) of a source. All modern DBMSs
provide a transaction mechanism to avoid this problem. A program signals the
start of a transaction, stores new values, then commits the transaction -- and
only at the commit point do all the new values appear in the database, as a
unit. If anything fails at any point before or during the commit, then the
database is automatically rolled back to the previous ``known good'' state,
that before the start of the transaction. While we can't easily implement
transactions with AIPS++ tables alone, we should certainly take it into account
while designing the interface. Therefore, something like

\begin{verbatim}
lsm.commit_source(source(s));
lsm.commit_all_sources();
\end{verbatim}

seems entirely appropriate. Future implementations can then employ transactions
inside these methods.

\subsubsection{The source as a compound object}

Up till now, I've treated the source parameters as completely independent
entities (except for the transaction discussion above), with each parameter
represented by its own MeqParm or subtree. But are they always? One could
imagine  an extended source where the brightness is a function of position.
Depending on how that is modelled, the nodes representing position may be
shared with the subtree representing brightness. For that matter, the  Stokes
parameters may all depend on the same MeqParm (spectral index?). This means that
you can't quite treat the parameter nodes (subtrees) separately from each
other, since they may share child nodes (and not just the leaf MeqParms --
maybe whole subtrees as well). On the other hand, you don't want the
application layer to bother with this complexity when defining trees.

Fortunately, this doesn't break the paradigm at all. Glish (and Python, and
most mature languages) allows objects to be multiply referenced. Consider:

\begin{verbatim}
i_rec := lsm.source_node(sources[i].id,'pol_stokes_i');
q_rec := lsm.source_node(sources[i].id,'pol_stokes_q');
\end{verbatim}

The {\tt i\_rec} and {\tt q\_rec} defrecs (more specifically, their {\tt
children} field) can refer to the same child defrec, representing a single
MeqParm (e.g. spectral index). This multiple reference can be set up inside the
{\tt lsm} object (via the Glish {\tt ref} statement). If a user wants to
construct a source on-the-fly, he can use the same technique.

On the {\tt MeqParm.define()} side of things, when you say:

\begin{verbatim}
i_index := MeqParm.define(name_i,i_rec);
q_index := MeqParm.define(name_q,q_rec);
\end{verbatim}

\noindent someone has to figure out that a node is shared. This can be
elegantly handled in {\tt define()} by {\em inserting the node index into the
defrec} once a node is created. So, the first {\tt define()} call above would
create the shared MeqParm (perhaps somewhere far down the subtree), and insert
a {\tt node\_index} field into its defrec. The second {\tt define()} call,
while recursively creating its own subtree, would eventually come across a
defrec with an already defined node index field. It would then know that this
node has already been created, and just use its index directly when creating
the parent node.

To conveniently address this data together, the source record (the one returned
by {\tt lsm.select\_sources()}) could actually include refs to the defrecs of
its parameters. This would allow the application layer to manipulate each
source as a single entity -- and easily address questions like, if this is the
source, what are its parameters' nodes, and what are their values?

\subsubsection{Where is the code?}

Note that in all of the examples above, no explicit GSM support is implied on
the C++ side, since everything is done in terms of generic MeqNode
functionality. Stuff specific to GSM/LSM can stay entirely on the scripting
side. This plays very well with the ``policy barrier'', and prevents extra
complexity from entering the C++ domain (as if it needed any extra complexity!)

Initial GSM/LSM support can thus be done entirely in Glish, with use of the
{\tt table.g} module and/or MEPdb functions (however those are
implemented). When Glish performance becomes an issue -- whether in the scope
of PSS4, or  further down the road -- critical parts can be reimplemented in
C++. (Besides, once the D-team adds support for a real DBMS, a lot of scripting
code is going to be phased out, so the performance issue may not come up at
all.) The really good thing about this is that Glish code represents relatively
little investment, compared to C++, from a man-hours/functionality point of
view. This will allow us to move forward rapidly, and go back for a more
in-depth implementation only when performance becomes a limiting factor.

\subsubsection{Some preliminary conclusions}

\begin{enumerate}

\item While the GSM as a data product (together with its support tools) is a
stand-alone beast, its design should be considered together with the MEPdb, as
it shares much of the underlying model.

\item Trees and GSM sources go hand-in-hand, since source parameters need 
to be represented by sub-trees.

\item Initial development (and perhaps all PSS4-scope development) can be done
rapidly in Glish.

\end{enumerate}

\subsection{Automatic source finding}

From an algorithmic standpoint, this is an entirely separate problem. The
AIPS++ {\tt image} tool provides a function for finding point sources
\cite{image-fs}. It remains to be determined how useful or functional this is.

The problem has also been widely studied in the literature, so, should the
power of AIPS++ prove not up to the task, there's a wealth of experience to
draw upon. In particular, the CLEAN algorithm \cite{clean} \cite{clean2} has
been widely used by radio astronomers to ``decompose'' an image into a set of
point sources.  Looking across disciplines, optical astronomers have worked on
similar problems for ages, for applications such as crowded-field photometry
(see, e.g., the DAOPHOT~II package \cite{daophot}).

From a data management point of view, any source finder, be it based on CLEAN
or something else, can be viewed as a ``black box'' that produces a collection
of point sources, given a set of images. This collection can be in the form of
a conventional list (positions/brightnesses), or perhaps an image (with each
non-zero pixel representing a point source). These lists or images may be
organized into data cubes, if frequency and polarization are taken into
account. However, as far as GSM design is concerned, these algorithmic issues
are completely orthogonal. Therefore, we can assume that we'll eventually have
a ``magic tool'' that can find sources in an image, and produce them in the form
of a source list. What are the implications for GSM?

\begin{itemize} 

\item The process can be handled entirely from the scripting side. Imaging 
will be done from Glish anyway; the tool can be applied to the initial dirty
image and/or to residual images produced by successive calibration steps.

\item Once the tool has produced a list of sources (as a minimum, position \&
brightness guesstimates), these can be turned into defrecs compliant with the
overall scheme, and appropriate MeqParms can be created and solved for.

\item Sources for which a solution is unsuccessful can be discarded (their
nodes trimmed from relevant trees). 

\item Sources solved for successfully can then be committed to the LSM. 
\end{itemize}

Note that this is effectively no different than having a user add sources
on-the-fly himself, which has already been touched upon in the discussion
above. The source of the sources, so to speak, is different, but further
mechanics would be the same. By handling the sources entirely in Glish, we can
rapidly  ``glue'' an automated source finder into the overall scheme of things.

\subsection{Database considerations}

The complex nature of GSM sources does not play well with the traditional
relational database at all, and thus presents a challenge for the database
designer. The fact that sources and parameters need to be represented in a
non-uniform way (images, shapelets, the whole zoo), and that there is complex
metastructure linking the parameters (e.g. subtrees), complicates matters
considerably. The full scope of this problem will have to be addressed by the
D-team. In the meantime, we need to outline a path within PSS4 and beyond.

\subsubsection{Prior art}

Astronomical catalogues of the first electronic generation were firmly rooted
in FORTRAN legacy. They were flat ASCII tables, with a uniform format for every
single source.\footnote{In fact, the {\em VizieR} service at CDS Strasbourg
\cite{vizier} -- the biggest consolidation of astronomical catalogues to date,
including the latest monsters such as USNO-B (over 1 billion objects!) still
specifies source catalog format in FORTRAN77 terms.} The shift to FITS Tables and/or
relational DBMSs did little to introduce any new paradigms, as a uniform table
format continued to be employed throughout\footnote{Though  (as a curious
sidenote) Rots et al. 2001 \cite{FEF} have proposed an embedded function format
for FITS binary tables. This represents multi-dimensional data in terms of
mathematical expressions of various parameters. While hardly relevant to our
purposes, this demonstrates that you can get a long way with a crusty old
format, given enough will and imagination!}. 
Any variability (in our case,
$t,f$ dependence) in the source was represented in the same some sort of fixed
and uniform format (via optionally-filled columns for proper motions, spectral
indices, a fixed set of bandpass fluxes, or perhaps spectra).

In the past several years, people have been looking towards object-oriented
databases (OODBs -- OODBMSs) to address the question of representing complex
and non-uniform data. A few examples:

\begin{itemize} 

\item Baruffolo \& Benacchio 1998 \cite{OODB3} have evaluated an
``object-relational'' approach, with a look towards implemeting complex queries
(i.e. region serach) and multidimensional indices. The engine employed was
PostgresSQL 6.0. 

\item The Science Survey Centre for the XMM-Newton mission has deployed an
object-oriented data depository for the mission's science products
\cite{OODB1}. This uses the now-discontinued O2 OODBMS. Their object model
includes more than 300 distinct classes. 

\item CDS Strasbourg has been evaluating OODB technology for their
SIMBAD\footnote{SIMBAD ``brings together basic data, cross-identifications,
observational measurements, and bibliography, for celestial objects outside the
solar system: stars, galaxies, and nonstellar objects within our galaxy, or in
external galaxies.

The acronym SIMBAD stands for Set of Identifications, Measurements, and
Bibliography for Astronomical Data.

SIMBAD contains information for about 1 million objects, for which 3.3 million
identifiers, more than 1.5 million observational measurements and 1.4 million
bibliographical references are available.''
(http://cdsweb.u-strasbg.fr/Simbad.html)} system \cite{OODB2}. The results (as
expected) did not match up too well, performance-wise, with SIMBAD's dedicated
C software (speed was 20\% to 75\% slower, and disk space consuption went up by
a factor of 3.) On the other hand, an OODBMS clearly offers far more powerful
capabilities where heterogenous data is concerned, and allows new features to
be added much more rapidly, while Moore's law mitigates the poorer performance,
making it even irrelevant in  some cases.

\item The AMASE project (Astrophysics Multi-spectral Archive Search Engine,
\cite{AMASE}, \cite{AMASE2}) consolidates heterogenous observational data from
several space missions. The project seems to be hibernating at the moment (the
last publication I could locate was from 1999, and their website hasn't been
modified since 2001). It uses (or used) the Informix-Illustra DBMS engine. The
last reported DB size was less than staggering --  on the order of $10^5$
entries, for a total size of 250Mb. 

\end{itemize}

Finally, the NVO effort is clearly taking the right approach by basing VOTable
on XML. XML excels at representing non-uniform structure of arbitrary
complexity. This makes VOTable a powerful {\em data interchange} format, but
does not address operational data management at all. Current NVO efforts are
mostly aimed towards converting the output of existing systems to VOTable form.

My conclusion is that while some current systems do deal with complex and
non-uniform data, they're geared towards archiving, research, and data mining.
The approach seems to be, make sure we store structure and throw all related
data at the user, and let him make sense of it. Catalogues employed in
operational use still use a fixed, uniform data format, with very minimal
representation of variability. And I could not find any parallels to the GSM
$\rightarrow$ LSM $\rightarrow$ calibration $\rightarrow$ LSM $\rightarrow$ GSM
cycle that we are contemplating here. Clearly, we're treading in unexplored
territory.\footnote{At least in the astronomy domain. It could be worthwhile to
cast an eye across other disciplines. Do gene-sequencing people perhaps deal
with similar problems?}

\subsubsection{Defining the scope for PSS4 \label{pss4scope}}

Given this complex problem, what can we hope to accomplish in PSS4? AIPS++
tables are not intended to represent complex non-uniform objects. As a
reasonable first-stage compromise, we can implement a uniform flat-table
structure such as that used by NEWSTAR, with a fixed set of MeqParms per each
source: 

\begin{itemize}
\item RA/Dec;
\item $I_0,Q_0,U_0,V_0$ fluxes;
\item Spectral index;
\item Rotation measure;
\item Spatial extent/orientation/ellipticity (for modelling extended sources with a 
2D Gaussian).
\end{itemize}

Note that this collection of MeqParms already implies construction of
sub-trees. For example, the Stokes $I$ of a source would be represented by a
subtree involving the $I_0$ MeqParm and the spectral index MeqParm. The {\em
knowledge} required to construct such a subtree would be hardwired into the
GSM code -- i.e. not yet reside in the database. (Implementation-wise, the
nested defrecs (see above) defining the sub-trees would be hard-wired in the
{\tt lsm} Glish code.)

This should allow us to play with complex source parameter representation
inside MeqTrees, while maintaining a simple AIPS++ table layout. We should
review the interface and the underlying data model, and answer the question,
does this satisfatorily provide for complex sources? Can we add them to the GSM
at a later date without breaking application-level scripts [too much]? For the
examples above, the answer seems to be ``yes''. These examples are, however,
just a departure point -- we will surely evolve the interface as the design is
elaborated. This is the question we should return to, to make sure it's
evolving in the right direction.

\subsection{Region search}

One of the most critical -- performance-wise -- functions of the GSM is that of
the region search (a.k.a. conesearch), as in, give me all the sources within
this field of view.\footnote{Additional search criteria -- such as brightness
cut-offs -- are certainly possible and should be supported. However, they are
mostly trivial algorithmically. The problem of selecting by coordinate is by
far the toughest nut, given a large enough database.} As the dataset grows
larger and larger, implementing this function efficiently becomes more
important, since existing databases do not provide intrinsic multidimensional
indexing capabilities of this kind. 

This has been studied by various astronomical data people at great
length, yielding various clever {\em sky indexing} schemes (see \cite{SI1},
\cite{SI2}, \cite{SI3} for a sampling).

Fortunately, the details of this can be completely hidden within the
implementation layer. The application layer need only expose a generic query
function. As far as PSS4 is concerned, we can probably get away with a simple
linear search of the entire database -- this is not an operation that happens
frequently, and the GSM is still small enough. In the future, we will
certainly have to implement true sky indexing. This may lie in the D-team
domain.

As a final note, NVO defines a ``Simple Cone Search'' interface for data
providers \cite{CS1}. This specifies a syntax for a web service that takes RA,
Dec \& search radius as arguments, and returns a VOTable of all sources within
the specified cone. It also imposes [very few] simple specifications on the
VOTable layout. Given a GSM$\rightarrow$VOTable conversion tool, and the region
search function, producing an NVO-compliant cone search service is a trivial
exercise. A list of currently available Cone Search services can be found at
\cite{CS2}. (Radio appears to be pathetically under-represented.)

\section{Stepwise implementation plan}

A proposed plan for implementing a GSM prototype and evolving it towards a
``production'' version:

\begin{enumerate}

\item Elaborate the design proposed here. Produce a few trial Glish scripts to
get a feel for the interface.

\item Finalize interface design. Develop an AIPS++ table structure along the
lines suggested in section \ref{pss4scope}.

\item Produce pilot GSM (GSM-1). This should be sufficient to 
support PSS4 targets.

\begin{itemize}
\item Associated software fully implemented in Glish;
\item Populated with 3C/4C sources;
\item Contains a detailed source model for 3C84;
\item Resulting size: $\approx$5000 sources;
\item All queries done via linear search.
\end{itemize}

\end{enumerate}

GSM-1 would already be a stand-alone data product, with a documented AIPS++
table format. As such, it could potentially be forked and extended by our
end-users.

It is difficult to plan specific steps beyond this stage, since there are
several parallel directions of development, and a large part of the work is
expected to move into the D-team domain. The following general directions
and/or milestones may be projected:

\begin{enumerate}
\item (D-team) Work towards a ``production'' implementation of the GSM
(GSM-2) using a commercial database engine. Besides the main body of database
design \& implementation work, this should also include:

\begin{enumerate}
\item Re-implementing the application interface layer in Python.
\item Implementing a backwards-compatible Glish interface to GSM-2 (if Glish support is
still required, which it probably will be). It should be possible to replace
GSM-1 with GSM-2 (this will probably imply an upgrade in MEPdb as well) 
without disrupting the rest of the PSS system.
\end{enumerate}

\item (R-team) Experiment with Cat II sources and tree representations of
complex extended sources. Add primitive support for storage of subtrees to
GSM-1. Full support should be provided by GSM-2.

\item Work on populating GSM-2 from larger and larger catalogues. The VizieR
service at CDS Strasbourg \cite{vizier} will be extremely useful here.

\item When the performance of linear search becomes unacceptable due to growing
size, implement a multidimensional indexing scheme for region search in GSM-2.

\item Develop a VOTable interface to GSM-2.
\end{enumerate}

\begin{sloppypar}
\begin{thebibliography}{99}

% alias for bibitem used here
\newcommand{\bibref}[1]{\bibitem{#1}}

\newcommand{\biburl}[1]{ {\tt\mbox{#1}}}

% creates a reference to an ADASS paper
% arguments: 1:label 2:author 3:year 4:title 5:volume 6:adass_roman_num
%            7:page 8:url
\newcommand{\adassref}[8]{\bibref{#1} #2 #3, {\em #4}, 
    in ASP Conf. Ser., Vol. #5 {\em(ADASS #6)}, #7,\biburl{#8}}

% shortcut for a references to specific ADASSes
% arguments: 1:label 2:author 3:title 4:page 5:url
\newcommand{\adassvii}[5]{\adassref{#1}{#2}{1998}{#3}{145}{VII}{#4}{#5}} 
\newcommand{\adassviii}[5]{\adassref{#1}{#2}{1999}{#3}{172}{VIII}{#4}{#5}} 
\newcommand{\adassix}[5]{\adassref{#1}{#2}{2000}{#3}{216}{IX}{#4}{#5}} 
\newcommand{\adassx}[5]{\adassref{#1}{#2}{2001}{#3}{238}{X}{#4}{#5}} 
\newcommand{\adassxii}[5]{\adassref{#1}{#2}{2003}{#3}{295}{XII}{#4}{#5}} 

\bibref{PSS4}Noordam, J.E.\ 2003, {\em Prototype Selfcal System 4 (PSS4)}, 
LOFAR-ASTRON-DOC-?????

\bibref{VOT}Williams, R. et al.\ 2002, {\em VOTable: A Proposed XML Format 
for Astronomical Tables},\\
\biburl{http://cdsweb.u-strasbg.fr/doc/VOTable/}

\bibref{UCD1}CDS 2002, {\em Unified Content Descriptors},\\
\biburl{http://vizier.u-strasbg.fr/doc/UCD.htx}

\bibref{UCD2}CDS 2002, {\em UCD Tools},\\
\biburl{http://vizier.u-strasbg.fr/UCD/}

\adassxii{UCD3}{Derriere, S. et al.}%
{Metadata for the VO: The Case of UCDs}{69}%
{http://adass.org/adass/proceedings/adass02/P1-1/}

\bibref{image-fs}AIPS++ Documentation, User Reference Manual, tool image,
function image.findsources\\
{\tt http://www.astron.nl/aips++/docs/user/General/\\
~~node54.html\#images:image.findsources.function}

\bibref{clean} Cornwell, T. \& Braun, R. 1989, {\em Deconvolution}, in Synthesis
Imaging in Radio Astronomy: Third NRAO Summer School 1988, ASP, 178

\bibref{clean2} {\em CLEAN Algorithm,}\\
{\tt http://scienceworld.wolfram.com/physics/CLEANAlgorithm.html}

\bibref{daophot} Stetson, P.\ 1992, {\em Initial Experiments With DAOPHOT II
and WFC Images}, in Third ESO/ST-ECF Data Analysis Workshop,
eds. P.J. Grosbol \& R.H. Warmels (Garching: ESO), 187

\bibref{vizier} {\em The VizieR Catalogue Service},\\
{\tt http://vizier.u-strasbg.fr/cgi-bin/VizieR}

\adassxii{OODB1}{Michel, L. et al.}{The XMM-Newton SSC
Database: Taking Advantage of a Full Object Data Model}{291}%
{http://adass.org/adass/proceedings/adass02/P5-7/}

\adassix{OODB2}{Wenger, M. et al.}{SIMBAD as a Test Bed for two Object 
Oriented Database Management Systems: Objectivity/DB and O2}{247}%
{http://adass.org/adass/proceedings/adass99/O9-06/}

\adassvii{OODB3}{Baruffolo, A. \& Benacchio, L.}{Object-Relational DBMSs 
for Large Astronomical Catalogue Management}{382}%
{http://adass.org/adass/proceedings/adass97/baruffoloa1.html}

\adassviii{AMASE}{Cheung, C. Y. et al.}{A Search and Discovery Tool --
AMASE}{213}%
{http://adass.org/adass/proceedings/adass98/cheungcy/}

\bibref{AMASE2}AMASE Project Website,\\
\biburl{http://amase.gsfc.nasa.gov/amase/WelcomeToAMASE.html}

\adassx{FEF}{Rots, A.H. et al.}{The FITS Embedded Function Format}{479}%
{http://adass.org/adass/proceedings/adass00/P1-33/}

\adassxii{SI1}{Ortiz, P.F.}{Why Indexing the Sky is Desirable}{35}%
{http://adass.org/adass/proceedings/adass02/O10-2/}

\adassxii{SI2}{Page, C. G.}{A New Way of Joining Source Catalogs using a
Relational Database Management System}{39}%
{http://adass.org/adass/proceedings/adass02/O10-4/}

\adassvii{SI3}{Wicenec, A.J. \& Albrecht, M.}{Methods for Structuring and 
Searching Very Large Catalogs}{512}%
{http://adass.org/adass/proceedings/adass97/wiceneca.html}

\bibref{CS1} NVO, {\em NVO Compliance: Conesearch},\\
\biburl{http://www.us-vo.org/metadata/conesearch/index.html}

\bibref{CS2} NVO, {\em VO Conesearch Profile Services},\\
\biburl{http://voservices.org/cone/register/showlist.asp}

\end{thebibliography}
\end{sloppypar}

\end{document}

