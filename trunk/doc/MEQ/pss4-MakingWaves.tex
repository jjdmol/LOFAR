\documentclass[12pt]{article}

\oddsidemargin=-5mm
\oddsidemargin=-5mm
\textwidth=170mm

\title{Event-Driven Trees: Making Waves}
\author{O. Smirnov \& G. van Diepen}

\begin{document}
\sloppy

\newcommand{\url}[1]{{\tt #1}}

\maketitle


\section{Introduction}
  
  During our (OMS, GvD) discussions with JEN over the design of MeqTrees, it
  has emerged that evaluation of MeqTrees should probably be asyncronous and
  event-driven. That is, evaluation should proceed on the basis of data
  availability. This documents attempts to elaborate this design, and looks at
  some wonderous implications for parallelization and other aspects of data
  processing. 

\section{Data-driven trees}

  In PSS3, evaluation of trees proceeded in an orderly and syncronous manner.
  Essentially, the calibration code would wait for an entire domain of data to
  be read in before doing any processing whatsoever. In current MeqTree
  terminology, this would correspond to loading all MeqSpigots with data before
  proceeding. 

  This is inefficient even in off-line, single-threaded mode, as the CPU
  remains essentially idle, waiting for all the data to arrive from the I/O
  subsystem. Looking at trees, it is obvious that upper subtrees (from the
  MeqSpigots down to the condeqs) could be evaluated for each individual
  MeqSpigot, all the way down to the condeq nodes, without any cross-dependence
  with other subtrees. Ideally, the CPUs could already be doing useful work as
  each MeqSpigot loads, rather than waiting for all of them to load. The
  benefits of this would be quite significant, especially on a massively
  parallel system and/or in on-line mode.

  Let's assume that we have some mechanism that would allow a child node to
  notify its parent(s)\footnote{The particular implementation of the
  notification mechanism is not that important for the time being. It will be
  discussed later on. In the final analysis, the notification eventually
  triggers a virtual callback function in the parent node. Note that the
  MeqResult could already be included in the notification.} whenever it becomes
  ``valid''. We'll call a node ``valid'' when it is capable of returning a
  MeqResult corresponding to a previously specified MeqRequest. In a nutshell,
  nodes would then behave as following:

  \begin{itemize} 
  
  \item A MeqSpigot notifies its parent(s) when it has been loaded with data,
  the data itself being the MeqResult.

  \item When a parent node receives notification from a child node, it checks
  if all its children are now valid. If so, it gets MeqResults from all its
  children, computes its own MeqResult, and notifies the grandparent.

  \end{itemize}
  
  Each chunk of data thus causes a ``ripple'' of MeqResults to travel down the
  tree, from a spigot to the lowermost node that can still be evaluated on the
  basis of already valid nodes. This creates a wave travelling down the tree,
  driven by data coming in from the top of the tree, all the way down to the
  Solvers. A Solver waits for all (or enough) of its condeqs to become valid,
  then proceeds with the solution.

  This allows the system to already compute as much information as possible
  {\em as the data is coming in.} 

  NB: Just to be clear on directions --- {\em up the tree} means from parent to
  child, from Solvers to MeqSpigots. {\em Down the tree} is the opposite. Now
  for the dirty details.

\subsection{Initialization}

  Nodes are initialized by a MeqRequest that travels recursively {\bf up} the
  tree, from parent to child. Among other things, a MeqRequest specifies the
  domain for which a MeqResult is required (for the examples here, let's
  assume a  10 second domain, with data coming in 1 second chunks).

  Note that a child may be able to satisfy a MeqRequest on the spot, if it
  already has all necessary data in its cache, or if its own children return
  valid MeqResults. In a fully-loaded and valid tree, this is always the case.
  Basically, evaluation of a loaded tree is pretty much equivalent to what
  happens in PSS3, and simply involves recursively traversing the tree. 
  
  If a node is unable to satisfy a MeqRequest, it returns a WAIT result. The
  node would probably clear its cache at this point (e.g., if the MeqRequest
  specified a new domain).

  In the simplest case of an unloaded tree, a MeqRequest would travel all the
  way up to each MeqSpigot. Spigots would then [re]configure themselves to
  expect data for the specified domain, and return WAIT to their parents. The
  parents would then also return WAIT, and so on back down the tree. At the
  bottom, the control script would receive a WAIT and go to sleep.

\subsection{MeqResult propagation}

  Once a MeqSpigot receives valid data for its domain, it notifies its
  parents. MeqResults then start percolating down the tree, as already
  described.
  
\subsubsection{Variable time resolution}

  Note that this scheme allows for time resolution to change along the tree, if
  {\em partial} MeqResults are allowed. In this and further examples, let's
  assume a 10 second domain, with data coming in 1 second intervals. Let's also
  assume that the topmost part of a tree -- from a MeqSpigot down to an
  integrator node -- can already evaluate data in 1 second chunks. The
  integrator node, on the other hand, requires a full 10 seconds to proceed.
  The spigot would generate 10 ``partial'' MeqResults, one per each interval.
  These would travel down to the integrator node. Once all 10 chunks are
  available, the integrator would do its thing, and send a single, full
  MeqResult down to its parents.
  
  Note that this smells somewhat like dynamically growing time domains, which
  we keep mentioning but never really elaborating. Perhaps we'll arrive at them
  by developing this line of thinking?

\subsubsection{End-of-data and MeqFails}

  How would we handle end of input data? The notification (or MeqResult)
  generated by a MeqSpigot should contain an EOD flag. This flag would then
  eventually propagate all the way down (to the control script).
  
  If we consider the integrator node in the previous example, it would
  certainly require the EOD flag to work properly. The flag would tell the
  integrator that no more intervals are coming down, so it must integrate with
  what is already available. Here's where the integrator can get clever. E.g.,
  if 8 intervals out of 10 are available, then it can still integrate and send
  down a MeqResult (also with an EOD flag). If, however, only 2 out of 10 are
  available, then it could send a MeqFail down to its parents.

  A MeqFail is a special kind of MeqResult, indicating failure. Most nodes
  would probably simply forward it down the tree (i.e., if any child has
  failed, then we have failed). The Solver, however, could still proceed even
  when some condeqs have failed (provided enough valid condeqs remain.)
  
  Note also that MeqFails should be generated by spigots that have found no
  data in the input stream (assuming it is sorted in order of time -- otherwise,
  a spigot will never know that it has failed to receive).

\subsubsection{Caching MeqResults}

  We assume that a parent node will know when its children should cache their
  MeqResults -- in other words, whether the parent will need to ask for the
  same MeqResult again. E.g., if none of the childrens' subtrees contain any
  solvable MeqParms, then the sub-tree's cumulative MeqResult will not change
  in subsequent solve iterations, so it can be cached at the root of the
  sub-tree, while the children do not need to retain cache. As a further
  optimization, Solvers may include a ``this is the final iteration'' flag in a
  MeqRequest, allowing nodes to clear caches as the final iteration proceeds.

  In any case, the command to clear cache goes up the tree, from parent to
  child. Care must be taken, though, in multiple-parent relationships (e.g.
  using ref counts or something, to make sure the cache is only cleared once
  the last parent renounces claims to it).

\subsection{Domain look-ahead}
  
  For efficiency's sake, a MeqSpigot could already look ahead to the next
  domain of data, even as the current domain is still being processed. To
  facilitate this, the initial MeqRequest should contain an optional hint of
  what the next domain is going to be (presumably, at the control script level,
  we already know what to expect from the data stream.) The spigot could then
  cache data chunks for the next domain as they become available. In the ideal
  case, a MeqSpigot will already have the next domain fully cached by the time
  the MeqRequest for it arrives.
  
  Caching beyond one domain is probably not practical. If the data stream is
  faster than our processing, a separate buffering scheme should be implemented
  upstream.

\subsection{A pre-conclusion}

  One reason we really like this scheme is because it implements complex global
  behaviour (i.e., data-driven result propagation through trees) based only on
  simple local (parent-child) interactions. Note that all of the behaviours
  above conform to the following policies:
  
  \begin{itemize}
  
  \item All control flows up the tree, from parent to child.
  
  \item Children have no knowledge of their parents, apart from delivering
  notifications and/or MeqResults (technically, some knowledge will be
  contained in the notification mechanism, but that does not change the logical
  model. We can't stress this point enough! The idea of children knowing their
  parents does not sit well at all with JEN -- well, they still don't know
  their parents as far as the design is concerned -- but C++ is a relatively
  low-level language that does not allow one object to set a watchpoint on
  another object, so we have to work around it in the implementation.)

  \item All nodes make decisions based only on the current MeqRequest and on
  the state of their children. No-one needs to know anything about the tree as
  a whole (apart from whoever builds it in the first place).

  \end{itemize}
  
  With that in mind, we can take the scheme a few steps further -- and most
  likely beyond the scope of an initial PSS4 implemetation. Hopefully this
  should demonstrate its wonderful usefulness.
  
  {\em JEN pacification note: no, we do not mean to implement the stuff below
  for the first stage of PSS4. The first stage stays simple. We do, however,
  want to keep all this in mind when elaborating the deign.}
  
\section{Self-peeling trees}

  The thinking on peeling in trees has been continously evolving. It's quite
  clear that trees can and will peel, the question is in the details.

  JEN has suggested a control ``masterscript'' that takes care of iterating
  over peel sources and domains. The system should certainly be flexible enough
  to allow anything from full manual control to any level of scripting. 
  
  We have realized that, given the above scheme, peeling can be implemented
  entirely in terms of trees, with no explicit external controls required.
  Consider, as a mental experiment:

  \begin{itemize}
  
  \item Each peel source has its own Solver, predict tree, etc. Trees for the
  second and each subsequent source contain special peel nodes, which are
  resposible for peeling previously solved-for sources from the visibility
  data. The sources need to be solved for and peeled in turn.
  
  \item Consider a peel node for source \#2. It has the following dependencies:
  a MeqSpigot to provide input data, and predicted visibilities for source \#1
  (which depend on the MeqParms being solved for.) Let's call this node {\em
  peel-1}. A peel node for source \#3 would, in turn, depend on peel-1 and on
  the predict for source \#2.
  
  \item Let's imagine the spigot and the predict sub-tree (predict-1) as
  [possibly grand-] children of peel-1. The MeqResult propagation scheme would
  cause peel-1 to evaluate itself as soon as data and a first predict for
  source \#1 become available. This is, of course, not quite what we want: we
  don't want to peel until a ``final'' predict is done, which could be after one
  or more iterations.

  There's various ways to get it right within the paradigm. Here's just a
  couple:

  \begin{enumerate}
  
  \item Have a ``valve'' node in between the predict-1 and peel-1 nodes. A
  valve node is very simple: it's either closed, in which case it ignores
  MeqResults from its child, or open, in which case it just forwards them to
  the parent(s). The valve is open or closed via an external event which could
  be generated from, e.g., a Solver. The first Solver would open the valve when
  initiating a final predict.

  \item Perhaps a cleaner (more data-driven) way would be to add a {\em type}
  tag to MeqRequests and MeqResults, and have the valve select on type.
  Intermediate and final predicts would be initiated via MeqRequests of
  different type. This type tag could be useful elsewhere, too.

  \end{enumerate}
  
  \item The entire ``forest'' would then look like a staggered set of
  interlinked trees. MeqResults would progpagate in a wave, starting at trees
  for source \#1, then on to \#2, etc., all the way to the last peeling source.
  
  {\em (NB: JEN sees peeling differently, with ``weighted sum'' nodes acting as
  selectors between peeling sources. This is an alternative way to design
  peeling trees; both kinds of trees should be possible if the basic toolbox is
  right. Using a wsum reduces the total number of nodes, so it would be
  preferable when running on a single machine. Interlinked trees such as
  proposed here would contain a much larger number of nodes, but, as will be
  shown below, could be spread over a cluster much more efficiently.}

  \end{itemize}
  
  This approach does not preclude looping over the peel sources one by one from
  a control script, as orignally proposed by JEN. This form of control should
  be available in any case. What this discussion shows, however, is that the
  concept of trees and waves is general enough to implement something as
  complex as source-by-source peeling fully within the paradigm, by connecting
  the right trees in the right sequence. No explicit external control is really
  necessary.
    
  Note that eliminating a single point of control and making peeling fully
  data-driven is very good for parallelization, since it eliminates a central
  syncronization point. In fact, we can take it one step further, and think
  about...

\section{A pipeline of waves}

  Consider a sequence of interlinked trees that implements peeling. For
  brevity's sake, let's call this a sequence of {\em forests}. Each forest is
  rooted at a single Solver, and deals with one peeling source. The forests are
  spread across machines in a cluster (this assumes that a tree can span
  multiple machines. This facility will have to be implemented, eventually).

  Data for one domain comes in through MeqSpigots and is processed by the first
  forest. Eventually, the first Solver becomes content, the first source is
  peeled, and the processing ``wave'' moves on to the second forest, to solve
  for source \#2.
  
  Now consider: at this point, the first forest could already start processing
  the next domain of data, thus starting a second processing wave. Eventually,
  you'll have forest $N$ peeling source $N$ for domain 1, forest $N-1$ peeling
  source $N-1$ for domain 2, all the way to forest 1 peeling source 1 for
  domain $N$. This achieves an high degree of parallelization, by splitting
  jobs crosswise between domain \& peel source simultaneously.

  The MeqResult propagation scheme requires very little extension to support
  multiple waves. Basically, we just need a mechanism to prevent waves from
  overrunning each other. Here's one possibilty:

  \begin{enumerate}
  
  \item Instead of one MeqRequest at a time, a whole queue of requests is sent
  up a tree (current domain (0), next domain (1), domain 2, etc.) Each node
  maintains its own queue.

  \item Once a parent node determines that a child's current MeqResult is no
  longer needed (see discussion on caching, above), it simply sends a
  NextRequest command up to the child. (As a trivial solution, a Solver could
  be the only node with this capability. However, more fine-grained parallelism
  could be achieved by allowing other nodes to initiate a NextRequest.)

  \item A node receiving a NextRequest command forwards it to all its children,
  and switches itself to the next MeqRequest in its queue. For a MeqSpigot
  node, this implies retrieving data for the next domain, and passing it back
  down the tree, once available. (This, in effect, opens the whole sub-tree,
  allowing the next wave to come through.)

  \item If a parent node receives notification from a child of a MeqResult for
  the next request, while still dealing with a previous request, it simply
  ignores it. (This keeps the next wave from overrunning the wave before it.)

  \end{enumerate}
  
  This requires a little further elaboration, but the basic idea is quite
  simple.
    

\end{document}

