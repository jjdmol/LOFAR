<?xml version="1.0"?>
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.1.2//EN"
 "http://www.oasis-open.org/docbook/xml/4.1.2/docbookx.dtd" 
 >

<!-- $Id$ -->
<!-- look at bottom for revision Log. -->
<article lang="en">
 <artheader>
  <title>use of the Blackboard architectural pattern in Selfcal</title>
  <author>
   <firstname>Daan</firstname>
   <surname>Hoogland</surname>
  </author>
  <releaseinfo>
   <para>
    $Id$
   </para>
   <para>

    This is a preliminary version, a concept.

   </para>
  </releaseinfo>

  <!-- makes a summary from the content -->
  <abstract>
   <para>

    For the LOFAR project a self-calibration program shall be written
    <xref linkend="LOFAR-ASTRON-ADD-006"/>. The idea is that this
    program will have the architectural structure of a
    "BlackBoard". Such a pattern caught in a framework will have
    broader use then just the self-calibration. The applicability of a
    framework following this design pattern will be investigated and a
    rapport hereof will be included in this document.

   </para>
  </abstract>
 </artheader>

 <section>

  <title>the blackboard architectural pattern</title>

  <para>

   The Blackboard pattern as shown in literature has many
   applications. They differ greatly in nature. The main feature of
   each and every one of those is that they work on (parts of) a
   problem by letting pieces of software (knowledge sources) take data
   from a central place (the blackboard), do with it whatever they can
   to get nearer to the solution, and put the results back to that
   central place.

  </para>

  <para>

   As described in <xref linkend="DAfPaDBBS" />, there are several
   levels at which to implement parallel Blackboard systems. In <xref
   linkend="PDR-CEP-Software" /> it is described how this applies to
   the imaging applications in the LOFAR Central Processor.

  </para>

  <para>

   In the case of the selfcal program, there is only one really
   important step that one takes in getting to the solution (calibrated
   data or measurement set). This is the predict-solve step. Though
   many of those steps shall be taken. Next to that, in the so called
   pealing strategy one can do a shift of the data-center in the UV
   data. And then there are some algorithms to decide if the present
   strategy is leading somewhere.

   <note>

    <para>

     It is assumed that the quality of a preliminary result can be measured.

    </para>

   </note>

  </para>

  <para>

   When paralleling the algorithm, it becomes very important that
   predict-solve steps or series thereof can be performed
   independently.

  </para>

 </section>

 <section>

  <title>LOFAR requirements</title>

  <para>

   LOFAR is a one-of system. There has never been anything build like
   it. The self-calibration solutions that instrumentalists and
   astronomers are thinking of are not yet developed. Several methods
   to perform a predict-solve step may be created for
   experimentation. Also several high level algorithms may be
   tried. The flexible architecture of the BlackBoard pattern is very
   well suited to insert both new low-level operations (the knowledge
   sources) as well as high level strategies (by configuring the
   controller(s)).

   <note>

    <para>

     It must be possible to add new knowledge sources to the system.

    </para>

    <para>

     It must be possible to configure controllers to react in a
     certain way to a certain state of the system.

    </para>

   </note>

  </para>

  <para>

   The Blackboard system to be build is going to allow the programmer
   to define a workload structure and a knowledge source that will
   react on such a workload. Finally (s)he will define a partial
   solution structure that results from the work. A controller will
   then recognize such a workload and assign it to a fitting knowledge
   source. It will be notified that a result is produced and think of
   what next step to take.

  </para>

  <para>

   Information on what type of knowledge source can take on what kind
   of workload will be stored in a database.

  </para>

  <para>

   It is expected that even in operational state the self-calibration
   will be under development. It might also put different demands on
   different observations. For this a library of control-strategies
   will be convenient. On top of that it will necessary to change or
   add control-strategies and low-level algorithms as we go.

   <note>

    <para>

     It would be nice to have a library of strategies that would
     include "conditions" and "actions to take".

    </para>

   </note>

  </para>

  <para>

   The blackboard architectural pattern facilitates this tweaking of
   different algorithms by its loose coupling. The different protocols
   between components in the system need to be very well specified for
   this.

  </para>

  <para>

   A knowledge source it's result definition must include an
   interpreter object that can return a quality of the result. For a
   controller it must be clear in what kind of new workload the result
   results.

  </para>

  <para>

   For fast invocation of calibration engines it might be a good idea
   to have them running as demons on nodes that &quot;might&quot; be
   used as predict/solve knowledge source hosts. this is one of the
   techniques described in <xref linkend="EMfaCOBBS"/>. However it is
   not to be expected that this will greatly enhance the execution
   speed as suggested in this paper, as our knowledge-sources will
   have longer execution times and less invocations.

  </para>

 </section>

 <section>

  <title>selfcal use of the blackboard pattern</title>

  <para>

   <mediaobject>blackboard-use_concept.png
    <imageobject>
     <imagedata fileref="blackboard-use_concept.png" format="PNG" />
     </imageobject>
    <caption>a simple topology for a distributed blackboard</caption>
   </mediaobject>

  </para>

 </section>

 <section>
  <title>a demo use-case</title>

  <section>
  <title>logical structure</title>
   <mediaobject>
    <imageobject>
     <imagedata fileref="demo.usecase.png" format="PNG" />
     </imageobject>
    <caption>a simple use-case for the blackboard based self-calibration</caption>
   </mediaobject>

   <para>

    This use-case is intended to demonstrate the use of the blackboard
    based architecture of the selfcal controller.

   </para>

   <para>

    The demo starts with the selection of a strategy, which currently is
    hand-/hard-coded in a python script. The strategy defines how the
    total processing job is split in subtasks that are controlled
    through their own BlackBoards. Also the strategy defines the subset
    of parameters that each Thread will solve for.

   </para>

   <para>

    The strategy chosen for this demo is as follows; The data set
    responsibility is split in two over time. After that the second part
    is split in three over frequency. As there is no real dataset
    involved we only let one BlackBoard control 'real' actions. the
    first child at top level is the lucky one. It starts three
    Thread/Controller instantiations with a quite similar set of
    parameters to solve. Each Thread gets the same parameters to work
    on. They all get responsibility over a distinct parameter. Also two
    of the Threads get a shared responsibility over a parameter. An
    extended demo could involve a Watcher that merges parameters at
    certain points in time. That is, the Watcher would feed back the
    (half-)solved parameters of the one Thread to the other.

   </para>

   <para>

    Now that the strategy is selected, the calibration can be performed.
    As defined in our strategy, the calibration is controlled by a
    hierarchy of six BlackBoard instantiations. The dataset is split
    over these BlackBoards, and now the responsibility over parameters
    is split as well.

   </para>

   <para>

    termination strategies can be "perform a fixed number of steps", or
    "terminate when &delta; smaller then &number;". This second
    approach can be dangerous, if the calibration process is not
    strictly convergent. For now the results are classified as good
    enough by the user terminating the program.

   </para>

   <para>

    After solving we can decide that our results are good enough. Or
    otherwise we continue solving with a modified selection of
    parameters per thread. This we will have to hard-code in the top
    level strategy. In this way we can demonstrate that we can solve for
    dependent parameters.

   </para>
   <para>
    <table frame='all' label="initial parameters" >
     <tgroup cols='4' align='left' colsep='1' rowsep='1'>
      <thead>
       <row>
        <entry>parameter</entry>
        <entry>assigned to 1</entry>
        <entry>to 2</entry>
        <entry>to 3</entry>
       </row>
      </thead>
      <tbody>
       <row>
        <entry>4.38187736305</entry>
        <entry>yes</entry>
        <entry>no</entry>
        <entry>no</entry>
       </row>
       <row>
        <entry>78.754188756</entry>
        <entry>no</entry>
        <entry>yes</entry>
        <entry>no</entry>
       </row>
       <row>
        <entry>6.27352461391</entry>
        <entry>no</entry>
        <entry>no</entry>
        <entry>yes</entry>
       </row>
       <row>
        <entry>75.4624074405</entry>
        <entry>yes</entry>
        <entry>yes</entry>
        <entry>no</entry>
       </row>
       <row>
        <entry>50.036219115</entry>
        <entry>yes</entry>
        <entry>no</entry>
        <entry>yes</entry>
       </row>
       <row>
        <entry>99.2854373037</entry>
        <entry>no</entry>
        <entry>yes</entry>
        <entry>yes</entry>
       </row>
      </tbody>
     </tgroup>
    </table>
    <note>
     <para>

      the responsibility over last three parameters is shared between
      two solution-threads and rotating over the three available
      threads. This is done to get an idea on how solution-threads can
      influence each other.

     </para>
    </note>

    The predict solve step is simulated by a simple formula that puts
    some inter-dependency in the parameters.

   </para>
  </section>

  <section>
   <title>implementation</title>

   <section>
    <title>requirements</title>
    <para>

     For the breadboard implementation python 2.3b1 is used.
     As well as postgres 7.3.3.
     At compile-time swig-1.3.19 is used.

    </para>
   </section>

   <section>

    <title>The strategy</title>
    <subtitle>A high level script</subtitle>

    <para>

     The implementation of the strategy is a python script using the
     components defined in the selfcal framework. In the final
     (c++-)implementation of selfcal. The high level control object is
     a process with an embedded python interpreter. It reads the script
     when started and in an advanced enterprise-pro-gold version it
     might supply a GUI to interrupt and/or change the strategy on the
     fly. The database used supplies the possibility to watch progress
     on-line and intervene if needed.

    </para>
   </section>

   <section>

    <title>the solver</title>
    <subtitle>A c++ stub</subtitle>

    <para>

     The code that makes parameters converge is:

     <programlisting>
      outparams[i] = itsParamValues[i] = 0.8*(itsParamValues[i] + i + 1) + 0.01*(itsParamValues[(i+1)%itsLen]);
     </programlisting>

     As can see neighbouring parameters are taken into account to
     emulate interdependencies. The full code can be found in <xref
     linkend="stub-code"/>

    </para>

   </section>

  </section>
  <section>
   <title>results</title>

   <para>

    resulting graphs

   </para>

   <para>
    <mediaobject id="all-results" >
     <imageobject>
      <imagedata fileref="results.png" format="PNG" />
      </imageobject>
     <caption id="all-results-caption" >all results</caption>
    </mediaobject>

    In figure &#x0022;<xref linkend="all-results" endterm="all-results-caption" />&#x0022; several parameters can be seen that
    are not being solved for.

   </para>

   <mediaobject>
    <imageobject>
     <imagedata fileref="param1.png" format="PNG" />
     </imageobject>
    <caption>first parameter</caption>
   </mediaobject>

   <mediaobject>
    <imageobject>
     <imagedata fileref="param3.png" format="PNG" />
     </imageobject>
    <caption>third parameter</caption>
   </mediaobject>

   <mediaobject>
    <imageobject>
     <imagedata fileref="1st.png" format="PNG" />
     </imageobject>
    <caption>first solution-thread</caption>
   </mediaobject>

   <mediaobject>
    <imageobject>
     <imagedata fileref="2nd.png" format="PNG" />
     </imageobject>
    <caption>second solution-thread</caption>
   </mediaobject>

   <mediaobject>
    <imageobject>
     <imagedata fileref="3rd.png" format="PNG" />
     </imageobject>
    <caption>third solution-thread</caption>
   </mediaobject>

  </section>

 </section>

 <appendix id="start script" >

  <title>strategy</title>

  <programlisting>
#!/usr/bin/env python

"""
The blackboard package

$Id$

"""
from bb.BlackBoard import BlackBoard;
from bb.Thread import Thread;
from bb.Controller import Controller;
from bb.Engine import Engine;
from util import paramset;
import util.pglist;

#import bb;


blb = BlackBoard();
blbEarlyChild = None;
blbLateChild = None;

# first get the list of children and the assign them, as can be seen
# at the sublevel this order can be reversed.

topLevelChildren = blb.split_over_time(2);
blbEarlyChild = topLevelChildren[0];
blbLateChild = topLevelChildren[1];

# Adjust the range for the second half of the observation.

blbLateChild.frequency(20,200);

# Initialize the children at the sublevel.

blbLateChildLowChild = None;
blbLateChildMiddleChild = None;
blbLateChildHighChild = None;

# Here we first put the children in the list and then assign them all
# at once. The catch is that you might assign (to) a list with the wrong length.

subLevelChildren = [blbLateChildLowChild, blbLateChildMiddleChild, blbLateChildHighChild];
subLevelChildren = blbLateChild.split_frequency(3);

# Now forget about all of this and work with one of the BlackBoards.
# make a set of assumptions for the parameters. These can be different
# in size for both engines.

numOfParams = 4;

# still fiddling with random in pyton.

paramset.unsetRandom();

ps = util.pglist.list2pgArray(paramset.mkParamSet(numOfParams));

# make the assignments:

##ja1 = util.pglist.list2pgArray(paramset.mkJobAssignment(numOfParams))
##ja1 = util.pglist.list2pgArray([False, True, False, False, True, True, True, False, False, False])
ja1 = util.pglist.list2pgArray([True, False, False, False]);
##ja2 = util.pglist.list2pgArray(paramset.mkJobAssignment(numOfParams))
##ja2 = util.pglist.list2pgArray([False, True, True, False, False, True, False, False, False, False])
ja2 = util.pglist.list2pgArray([False, True, True, False]);
##ja3 = util.pglist.list2pgArray(paramset.mkJobAssignment(numOfParams))
##ja3 = util.pglist.list2pgArray([False, True, True, False, False, True, False, False, False, False])
ja3 = util.pglist.list2pgArray([False, False, True, True]);

# initialize the workloads

wl1 = {};
wl2 = {};
wl3 = {};

wl1["parameterset"] = ps
wl1["jobassignment"] = ja1;
wl1["status"] = "new";

wl2["parameterset"] = ps 
wl2["jobassignment"] = ja2;
wl2["status"] = "new";

wl3["parameterset"] = ps 
wl3["jobassignment"] = ja3;
wl3["status"] = "new";

# create thread (starts)

thr1 = Thread(wl1);
thr2 = Thread(wl2);
thr3 = Thread(wl3);

# create controllers for those threads:

thr1cntrl = Controller(thr1);
thr2cntrl = Controller(thr2);
thr3cntrl = Controller(thr3);

# create the engines to work with:

eng1 = Engine();
eng2 = Engine();
eng3 = Engine();

# assign the engines to the threads:

thr1cntrl.addEngine(eng1);
thr2cntrl.addEngine(eng2);
thr3cntrl.addEngine(eng3);

# register the knowledge sources for (execution)thread control.

blbEarlyChild.register(thr1cntrl);
blbEarlyChild.register(thr2cntrl);
blbEarlyChild.register(thr3cntrl);
blbEarlyChild.register(eng1);
blbEarlyChild.register(eng2);
blbEarlyChild.register(eng3);

# all done start the calibration

blbEarlyChild.start();

# the program may not be ended as this gets to the screen. Then again
# it might.
import time;
time.sleep(10)

print "this is the end"
  </programlisting>

 </appendix>

 <appendix id="stub-code" >

  <title>solver stub code</title>

  <programlisting>
//  SelfcalEngineStub.h: one line description
//
//  Copyright (C) 2002
//  ASTRON (Netherlands Foundation for Research in Astronomy)
//  P.O.Box 2, 7990 AA Dwingeloo, The Netherlands, seg@astron.nl
//
//  This program is free software; you can redistribute it and/or modify
//  it under the terms of the GNU General Public License as published by
//  the Free Software Foundation; either version 2 of the License, or
//  (at your option) any later version.
//
//  This program is distributed in the hope that it will be useful,
//  but WITHOUT ANY WARRANTY; without even the implied warranty of
//  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
//  GNU General Public License for more details.
//
//  You should have received a copy of the GNU General Public License
//  along with this program; if not, write to the Free Software
//  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
//
//  $Id$

#include "SelfcalEngineStub.h"

#include &#x003C;unistd.h&#x003E;
#include &#x003C;iostream&#x003E;
#include &#x003C;ostream&#x003E;


SelfcalEngineStub::SelfcalEngineStub():itsParamValues(NULL) {
  std::cout &#x003C;&#x003C; "SelfcalEngineStub Constructor " &#x003C;&#x003C; std::endl;
}

SelfcalEngineStub::~SelfcalEngineStub() {
  std::cout &#x003C;&#x003C; "SelfcalEngineStub Destructor " &#x003C;&#x003C; std::endl;
  if (itsParamValues != NULL) delete[] itsParamValues;
}

void SelfcalEngineStub::init(int len,
			     float parameters[]) {
  if (itsParamValues != NULL) delete[] itsParamValues;
  itsLen = len;

  itsParamValues = new float[len];
  for (int i=0; i&#x003C;len; i++) {
    itsParamValues[i] = parameters[i];
  }
}

float * SelfcalEngineStub::Solve(bool    *workdef, 
                                  float   outparams[]) {

  std::cout &#x003C;&#x003C; "start Solving" &#x003C;&#x003C; std::flush;
  for (int i=0; i&#x003C;itsLen; i++) {
    //sleep(1);
    std::cout &#x003C;&#x003C; "." &#x003C;&#x003C; std::flush;

    if (workdef[i] == true) {
      outparams[i] = itsParamValues[i] = 0.8*(itsParamValues[i] + i + 1) + 0.01*(itsParamValues[(i+1)%itsLen]);
      std::cout &#x003C;&#x003C; i &#x003C;&#x003C; " " &#x003C;&#x003C; outparams[i] &#x003C;&#x003C; "  ";
    }
  }
  std::cout &#x003C;&#x003C; "OK" &#x003C;&#x003C; std::endl;;
  
  return outparams;
  
}


void SelfcalEngineStub::dump() {
  for (int i=0; i&#x003C;itsLen; i++) {
    std::cout &#x003C;&#x003C; itsParamValues[i] &#x003C;&#x003C; " ";
  }
  std::cout &#x003C;&#x003C; std::endl;
  </programlisting>

 </appendix>

 <appendix>

  <title>revision log</title>

  <para>

   Hand copy log entries from the cvs log, or make up your own.

  </para>

  <para>

   <itemizedlist>

    <listitem>
     <para>
      Revision 1.1 2003/06/18 12:06:25 daan
     <para>
     </para>
      frame and appendix for revision entries
     </para>
    </listitem>

   </itemizedlist>

  </para>

 </appendix>

 <bibliography>
  <title>References</title>

  <bibliodiv><title>Books</title>

   <biblioentry xreflabel="nii">
    <abbrev>BBAnA</abbrev>
    <authorgroup>
     <author>
      <firstname>Penny</firstname>
      <surname>Nii</surname>
     </author>
    </authorgroup>
    <copyright>
     <year>1989</year>
     <holder>Academic Press Inc.</holder>
    </copyright>
    <editor>
     <firstname>B.</firstname>
     <surname>Chandrasekaran</surname>
    </editor>
    <isbn>0-12-379940-6</isbn>
    <publisher>
     <publishername>Academic Press Inc.</publishername>
    </publisher>
    <title>Blackboard Architectures and Applications</title>
    <subtitle>Introduction</subtitle>
    <pagenums>xix-xxix</pagenums>
   </biblioentry>

  </bibliodiv>

  <bibliodiv>
   <title>articles</title>
 
   <biblioentry id="EMfaCOBBS">
    <title>EFFICIENCY MECHANISMS FOR A CLASS OF BLOACKBOARD SYSTEMS</title>
    <abbrev>Efficiency</abbrev>
    <authorgroup>
     <author>
      <firstname>Ratikorn</firstname>
      <surname>Hewett</surname>
     </author>
     <author>
      <firstname>Micheal</firstname>
      <surname>Hewett</surname>
     </author>
    </authorgroup>
   </biblioentry>
 
   <biblioentry id="DAfPaDBBS">
    <title>Design Alternatives for Paralel and Distributed Blackboard Systems</title>
    <abbrev>Design Alternatives</abbrev>
    <authorgroup>
     <author>
      <firstname>Daniel</firstname>
      <surname>Corkill</surname>
     </author>
    </authorgroup>
   </biblioentry>

  </bibliodiv>

  <bibliodiv>
   <title>LOFAR documentation</title>

   <biblioentry  id="LOFAR-ASTRON-ADD-006" >
    <title>LOFAR Architectural Design Document</title>
    <author>
     <surname>Schaaf</surname>
     <firstname>Kjeld</firstname>
     <othername>van der</othername>
    </author>
    <copyright>
     <year>2002</year>
     <holder>ASTRON</holder>
    </copyright>
   </biblioentry>

   <biblioentry id="LOFAR-ASTRON-MEM-035" >
    <title>CEP Requirements Analysis, Architectural Design and Description</title>
    <author>
     <surname>Schaaf</surname>
     <firstname>Kjeld</firstname>
     <othername>van der</othername>
    </author>
    <copyright>
     <year>2002</year>
     <holder>ASTRON</holder>
    </copyright>
   </biblioentry>

   <biblioentry id="PDR-CEP-Software" >
    <title>CEP Software implementations</title>
    <author>
     <surname>Schaaf</surname>
     <firstname>Kjeld</firstname>
     <othername>van der</othername>
    </author>
    <copyright>
     <year>2003</year>
     <holder>ASTRON</holder>
    </copyright>
   </biblioentry>

  </bibliodiv>

 </bibliography>

</article>

<!--
$Log$
Revision 1.5  2003/06/24 17:35:36  daan
rough scetch

Revision 1.4  2003/06/19 17:42:54  daan
some syntax

Revision 1.3  2003/06/19 15:24:56  daan
conclusions

Revision 1.2  2003/06/18 17:26:47  daan
start makeing conclusions, man\!

Revision 1.1  2003/06/18 12:06:25  daan
frame and appendix for revision entries

 -->
<!-- eof $Id$ -->