<?xml version="1.0"?>
<!DOCTYPE article PUBLIC "-//OASIS//DTD DocBook XML V4.1.2//EN"
 "http://www.oasis-open.org/docbook/xml/4.1.2/docbookx.dtd" 
 >

<!-- $Id$ -->
<!-- look at bottom for revision Log. -->
<article lang="en">
 <articleinfo>
  <title>the implementation details of selfcal</title>
  <subtitle>the implementation details of the Blackboard
  architecture in the selfcal imaging application in LOFAR</subtitle>
  <authorgroup>
   <author>
    <firstname>Daan</firstname>
    <surname>Hoogland</surname>
   </author>
   <author>
    <firstname>Kjeld</firstname>
    <surname>Schaaf</surname>
    <othername role='conjectives'>van der</othername>
   </author>
  </authorgroup>
  <releaseinfo>
   <para>
    $Id$
   </para>
   <para>

    This is a preliminary version, a concept.

   </para>
  </releaseinfo>

  <!-- makes a summary from the content -->
  <abstract>
   <para>

    For the LOFAR project a self-calibration program shall be
    written. The idea is that this program will have the architectural
    structure of a "BlackBoard". The design and implementation details
    of this application, are described here.

   </para>
  </abstract>
 </articleinfo>

 <section>

  <title>introduction</title>

  <section>

   <title>Purpose of this document</title>

   <para>

    This document describes how the Blackboard architectural pattern
    is implemented to fit the need and requirement for the LOFAR
    self-calibration-application.

   </para>

  </section>

 </section>

 <section>

  <title>data-storage</title>

  <para>

   The major classes of storage requirements are

   <itemizedlist>

    <listitem>
     <para>

      parameters

     </para>

    </listitem>

    <listitem>
     <para>

      datasets

     </para>

    </listitem>

    <listitem>

     <para>

      the strategy

     </para>

    </listitem>

    <listitem>

     <para>

      the blackboard logistics

     </para>

    </listitem>

   </itemizedlist>

  </para>

  <section>

   <title>Parameter administration</title>

   <para>

    Parameters are solved locally, on subclusters of the LOFAR central
    processor and then distributed or discarded along the rest of the
    cluster.

   </para>

   <mediaobject>
    <imageobject>
     <imagedata fileref="local-_global-commit.png" format="PNG" />
     </imageobject>
    <caption>a simple topology for a distributed blackboard database</caption>
   </mediaobject>

   <para>

    In the distributed selfcal program, the available cluster will be
    partitioned as well as the data the be calibrated on. several
    sub-clusters will have responsibility over part of the data and hence
    part of the parameters  to be calibrated.

   </para>

   <para>

    A calibrating cluster is a set of programs running on a (set of)
    node(s), that is doing part of the calibration.
    A calibrating cluster might use more parameters then it has
    responsibility over. Therefor it must have all parameters to its
    disposal.

   </para>

   <para>

    A calibrating cluster is converging parameters from assumed values
    to corrected values. This converging might go in the wrong direction
    so a set of transactions might be leading to invalid results and
    must not be distributed. It might also lead to good results and be
    approved by a controlling program for distribution. The idea is that
    this program will then close a more global transaction, leading to
    the replication of the data.

   </para>

   <para>

    The essence of the requirement is that transactions have to be
    nested. The fact that they seem to be centered around separate
    engines does not seem to be important. We need only one level of
    nesting.

   </para>

   <section>
    <title>nested cooperative transactions</title>

    <para>

     One solution for this requirement is that transactions can be
     nested. The fact that they seem to be centered around separate
     engines does not seem to be important. We need only one level of
     nesting. However several processes with their own connections to
     the database must be able to participate in a single global level
     transaction.

    </para>

    <mediaobject>
     <imageobject>
      <imagedata fileref="database.png" format="PNG" />
      </imageobject>
     <caption>the action sequence that asks for nested transactions</caption>
    </mediaobject>

    <para>

     For this nesting to make sense, a database client must be able to
     start a transaction and get an transaction id to distribute among
     co-workers.

    </para>

    <para>

     These co-workers can then work on the global transaction, by
     &quot;"connecting to"&quot; or &quot;"joining"&quot; a transaction
     by id. Once joined, they can change data within the scope of global
     transaction. This can be as singular operations or as
     transactions. Any changes committed is valid an visible to any
     client joining in the transaction. Once the owner decides so he can
     close the global transaction. This closing can be a commit as well
     as a rollback, both with the expected result.

     <note>

      <para>

       Should participants be notified of the closing of the transaction?

      </para>

      <para>

       No, they will notice when trying to manipulate data.

      </para>

   ` </note>

    <mediaobject>
     <imageobject>
      <imagedata fileref="nestedTransaction.png" format="PNG" />
      </imageobject>
     <caption>sample sequence of a nested transaction</caption>
    </mediaobject>

    </para>

   </section>

   <section>
    <title>selective replication</title>

    <para>

     Another solution would be to use selective replication. This could
     mean that records will only be replicated after a specific
     trigger. It could also mean that only part of the datamodel will be
     replicated to other engines.

    </para>

   </section>
  </section>

  <section>

   <title>Datasets</title>

   <para>

    Datasets are high-volume and intensively queried. Updates are
    mostly copies. Using a database engine would be to much of a
    CPU-cycle and memory hog.

   </para>

  </section>

  <section>

   <title>The strategy</title>
   <subtitle>A high level script</subtitle>

   <para>

    The implementation of the strategy is a python script using the
    components defined in the selfcal framework. In the final
    (c++-)implementation of selfcal, the high level control object is
    a process with an embedded python interpreter. It reads the script
    when started and executes it, creating the processes needed on the
    nodes available to the program.

   </para>

   <para>

    In an advanced enterprise-pro-gold version the control object
    might supply a GUI to interrupt and/or change the strategy on the
    fly. The database used supplies the possibility to watch progress
    on-line and intervene if needed.

   </para>

   <para>

    The in core storage of the script byte be python byte code, but it
    might be a database as well. It must be taken into account that
    user representation of both database and in-core code, will be
    hard to implement.

   </para>

    <mediaobject>
     <imageobject>
      <imagedata fileref="strategy_interpreter.png" format="PNG" />
      </imageobject>
     <caption>sample sequence of a nested transaction</caption>
    </mediaobject>

  </section>

  <section>

   <title>The blackboard logistics</title>

   <para>

    For the blackboard to function several protocols need to be
    described. To guarantee loose coupling between components it is
    not desirable to have the dialogs in these protocols be needing
    real-time message interchange. Therefor a database-based approach
    is chosen, which is described in
    <xref linkend="logistical datamodel"/>.

   </para>

  </section>

 </section>

 <section>
  <title>distributed hierarchical blackboard</title>

  <section>
   <title>distribution over nodes and sub-clusters</title>
   <para>

    For performance reasons we want to divide the measurement data over
    the cluster in a way that distributes the disk-usage and minimizes
    the network-usage.

   </para>

   <para>

    Logically there is only one Blackboard. It is a distributed
    application however, each instance dividing it's workload to it's
    own liking. Each blackboard <note>no capital here</note> knows what
    nodes it has to start KnowledgeSources on.

   </para>

   <para>

    For this to work it has to be possible to distribute responsibility
    in this fashion as well. For instance; If a blackboard has
    responsibility for a certain time-frame, it must be able to change
    any time dependent parameters at will as long as they fall
    completely in this time frame. <note>Continuity in a function for a
    parameter over time will pose a problem at the edges of the time
    frame.</note>

   </para>

  </section>

  <section>
   <title>Workload distribution</title>
   <para>

    The workload for a self-calibration process, might be distributed
    in several ways. It is a design choice to decide that only
    partitioning to data, as opposed to partitioning to parameters, is
    opportune. This is based on the order of magnitude that the volume
    of data is bigger then the amount of parameters. The data has a
    limited number of dimensions. <note>The number of dimensions is four as far as
    we can tell right now</note> These are.

    <itemizedlist>
     <listitem>
      <para>
       time
      </para>
     </listitem>
     <listitem>
      <para>
       frequency
      </para>
     </listitem>
     <listitem>
      <para>
       baseline
      </para>
     </listitem>
     <listitem>
      <para>
       observatory-direction
      </para>
     </listitem>
    </itemizedlist>

    The Blackboard will be configured to delegate tasks to children,
    divided along one of these dimensions.<note>It doesn't seem
    necessary to divide along a dimension more then once.</note>

   </para>
  </section>

  <section>
   <title>controllers</title>
   <para>

    A Blackboard has a controller that can be asked to start a process
    for a blackboard. Such a process can be a child-blackboard
    including its controller, or one of the knowledge sources
    associated with the blackboard.

   </para>
  </section>

  <mediaobject>
   <imageobject>
    <imagedata fileref="start.usecase.png" format="PNG" />
    </imageobject>
   <caption>start of systeem</caption>
  </mediaobject>

 </section>

 <section id="logistical datamodel" xreflabel="logistical datamodel">

  <title>logistical database</title>
  <section>

   <title>Workload distribution</title>
   <para>

    The data, resulting from an observation will be several TB in
    volume <xref linkend="LOFAR-ASTRON-MEM-035" />. To
    conveniently handle this it will have to be partitioned. To handle
    part of the data a specialized sub-cluster will be defined. (see <link
    linkend="subcluster" >Figure 1</link>).

   </para>

    <mediaobject id="subcluster">
     <imageobject>
      <imagedata fileref="bb.subcluster.png" format="PNG" />
     </imageobject>
     <caption>Figure 1: an example subcluster</caption>
    </mediaobject>

   <para>

    As a result of this partitioning the Blackboard will be responsible
    for a subset of the data. This it will know:

   </para>
   <para>

    {self}1, {parent-id}1, {range}1

    <itemizedlist>
     <listitem>
      <para>

       "self" is the id of this blackboard.

      </para>
     </listitem>
     <listitem>
      <para>

       "parent_id" is the obvious.

      </para>
     </listitem>
     <listitem>
      <para>

       "range" is the set of values that defines the dataset used for
       solving parameters.

      </para>
     </listitem>
    </itemizedlist>

   </para>
   <para>

    the range can vary over several dimensions

   </para>
   <para>

    {time}1, {frequency}1, {interferometers}1, {direction}1
    <itemizedlist>
     <listitem>
      <para>

       "time" is a time range this blackboard is concerned
       with. <note>We'll assume no time-gaps for now.</note>

      </para>
     </listitem>
     <listitem>
      <para>

       "frequency" is the frequency range or band this blackboard is
       concerned with.  <note>We'll assume a single continuous band for
       now.</note>

      </para>
     </listitem>
     <listitem>
      <para>

       "interferometers" is the set of baselines that this BlackBoard is
       responsible for.

      </para>
     </listitem>
     <listitem>
      <para>

       "directions" is a range of points in the sky that function as
       field-centers.

      </para>
     </listitem>
    </itemizedlist>

   </para>
   <para>

    If for some reason it is considered that on one of the dimensions
    the range to evaluate is to large to do in one step, the Blackboard
    can ask it's BlackBoardController to spawn children. The Blackboard
    will have to know what children it has:

   </para>
   <para>

    {child-id}1, {self}1, {range}1

   </para>
   <para>

    For all of "time" through "objects" goes that they are a subset of
    the parents fields with the same name.

   </para>


  </section>

  <section>
   <title>Workload level</title>
   <para>

    The idea is that several analysis threads can exist
    simultaneously. In each of these threads several processes are
    active. In our blackboard model we have the following
    Knowledge-Sources

    <itemizedlist>
     <listitem>
      <para>

       A SelfCalEngine. Which contains processes at several
       nodes. There are a solve process and an array of predict
       processes.

      </para>
     </listitem>
     <listitem>
      <para>

       A SelfCalController starts engines and forks new child-threads
       if opportune.

      </para>
     </listitem>
     <listitem>
      <para>

       A SelfCalWatcher that monitors threads and decides on what is or
       is not a dead end.

      </para>
     </listitem>
    </itemizedlist>


    All three have their controlling BB tables.

    <section>
     <title>SelfcalEngine</title>
     <para>

      A SelfcalEngine solves for a set of parameters based on part of the data.

     </para>
     <para>

      A SelfcalEngine writes a record with globally the following
      structure.

     </para>
     <para>

      {meta-data}1, {next-action-type}1, {quality}1, {p-name, p-value, p-delta}1-*

     </para>
     <para>

      meta-data will contain:

     </para>
     <para>

      {workload-id}1, {engine-id}1, {controller-id}1, {parent-id}1, {range}1

      <itemizedlist>
       <listitem>
        <para>

         the id for the SelfcalEngine that produced the result.

        </para>
       </listitem>
       <listitem>
        <para>

         the id for the SelfcalController that created the workload.

        </para>
       </listitem>
       <listitem>
        <para>

         The parent id of this workload. This could be a thread-id or
         the id of another workload.

        </para>
       </listitem>
       <listitem>
        <para>

         The time that the data was captured.

        </para>
       </listitem>
       <listitem>
        <para>

         The frequency-range examined.

        </para>
       </listitem>
      </itemizedlist>

     </para>

    </section>

    <section>
     <title>SelfcalController</title>
     <para>

      A SelfcalController writes records of workloads like the
      SelfcalEngine, except the it does give a quality and it doesn't
      write the SelfcalEngine id. An engine writes its id in a record
      as it accepts it and starts the associated calculation. When it
      is finished it writes the deltas for all parameters and the
      quality.

     </para>
     <para>

      A SelfcalController decides what the next step in a anaysis path
      should be. The range might be smaller then that of the parent
      dataset.

     </para>
     <para>

      {controller-id}1, {strategy-description}1, {range}1, {child-id}0-*

     </para>
    </section>
    <section>
     <title>SelfcalWatcher</title>
     <para>

      A SelfcalWatcher has to have access to the records of the
      engines. It has a domain to watch containing several analysis
      threads.

     </para>
     <para>

      {watcher-id}1 {controller-id}2-*

     </para>
    </section>
   </para>
  </section>
 </section>

 <appendix>

  <title>revision log</title>

  <para>

   Hand copy log entries from the cvs log, or make up your own.

  </para>

  <para>

   <itemizedlist>

    <listitem>
     <para>
      Revision 1.1 2003/06/18 12:06:25 daan
     <para>
     </para>
      initial version containing:
      <itemizedlist>
       <listitem>
        <para>
         storage requirements.
        </para>
       </listitem>
      </itemizedlist>
     </para>
    </listitem>

   </itemizedlist>

  </para>

 </appendix>

 <bibliography>
  <title>References</title>

  <bibliodiv>
   <title>LOFAR documentation</title>

   <biblioentry id="LOFAR-ASTRON-MEM-035" >
    <title>CEP Requirements Analysis, Architectural Design and Description</title>
    <author>
     <surname>Schaaf</surname>
     <firstname>Kjeld</firstname>
     <othername>van der</othername>
    </author>
    <copyright>
     <year>2002</year>
     <holder>ASTRON</holder>
    </copyright>
   </biblioentry>

  </bibliodiv>

 </bibliography>

</article>
<!--
$Log$
Revision 1.4  2003/06/24 17:35:36  daan
rough scetch

Revision 1.3  2003/06/19 17:42:55  daan
some syntax

Revision 1.2  2003/06/19 15:24:56  daan
conclusions

Revision 1.1  2003/06/18 17:26:47  daan
start makeing conclusions, man\!


 -->
<!-- eof $Id$ -->