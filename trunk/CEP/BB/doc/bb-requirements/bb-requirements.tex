% ----------------------- Preamble
\documentclass[]{lofar}
\usepackage{layout}

\include{definitions} %local definitions

%\usepackage{amsmath,amsthm, amsfonts, amssymb, amsxtra,amsopn}
%\usepackage{graphicx}
\usepackage{float}
%\usepackage{times}
\usepackage{fancybox}
%\usepackage{algorithmic}
\usepackage[dvips]{hyperref}
%\usepackage{theorem}
\DeclareGraphicsExtensions{.eps}

\floatstyle{boxed}
\newfloat{assumption}{ht}{ass}[section]
\floatname{lessonlearned}{Lesson learned}
\newfloat{lessonlearned}{H}{les}
%\newfloat{prerequisite}{ht}{pre}[section]
\newfloat{requirement}{ht}{req}[section]

% ------------------------  End of Preamble.
\begin{document}

  \maketitle

  \begin{abstract}

    The use of the Blackboard architectural pattern, in the LOFAR
    Central Processor, for the selfcal control system.  For the LOFAR
    project a self-calibration program shall be written
    \hyperlink{LOFAR-ASTRON-ADD-006}{[SCH02-1]}. The idea
    is that this program will have the architectural structure of a
    "BlackBoard". Such a pattern caught in a framework will have
    broader use then just the self-calibration. The applicability of a
    framework following this design pattern will be investigated and a
    rapport hereof will be included in this document.

  \end{abstract}

  \tableofcontents

  \listoffigures

  \listoftables

  \section{the blackboard architectural pattern}
  \label{sec:blackboard-architectural-pattern}

    The Blackboard pattern as shown in literature has many
    applications. They differ greatly in nature. The main feature of
    each and every one of those is that they work on (parts of) a
    problem by letting pieces of software (knowledge sources) take
    data from a central place (the blackboard), do with it whatever
    they can to get nearer to the solution, and put the results back
    to that central place.

    As described in \hyperlink{bib:Design-Alternatives}{[COR89]}, there are
    several levels at which to implement parallel Blackboard
    systems. In \hyperlink{bib:PDR-CEP-Software}{[SCH03]} it is
    described how this applies to the imaging applications in the
    LOFAR Central Processor.

    In the case of the selfcal program, there is only one really
    important step that one takes in getting to the solution
    (calibrated data or measurement set). This is the predict-solve
    step. Though many of those steps shall be taken. Next to that, in
    the so called peeling strategy one can do a shift of the
    data-center in the UV data. And then there are some algorithms to
    decide if the present strategy is leading somewhere.

    \begin{assumption}
      It is assumed that the quality of a preliminary result can be
      measured.
      \caption{ quality of a preliminary result\label{ass:quality}}
    \end{assumption}

    When paralleling the algorithm, it becomes very important that
    predict-solve steps or series thereof can be performed
    independently. Such loose coupling of steps that lead to a final
    solution is a distinct quality of the blackboard architectural
    pattern.

    \begin{assumption}
      For the Blackboard to be useful in the self-calibration context
      it is assumed that the self-calibration algorithm can be
      partitioned over the dimensions of the dataset, or at least that
      parameters can be solved for independently.
      \caption{data partitioning\label{ass:partitionable}}
    \end{assumption}

  \section{LOFAR requirements on the selfcal control system}
  \label{sec:LOFAR-requirements}\hypertarget{sec:LOFAR-requirements}{}

    LOFAR is a one-of system. There has never been anything build like
    it. The self-calibration solutions that instrumentalists and
    astronomers are thinking of are not yet developed. Several methods
    to perform a predict-solve step may be created for
    experimentation. Also several high level algorithms may be
    tried. The flexible architecture of the BlackBoard pattern is very
    well suited to insert both new low-level operations (the knowledge
    sources) as well as high level strategies (by configuring the
    controller(s)).

    \begin{requirement}
      It must be possible to add new knowledge sources to the system.
      \caption{new knowledge sources\label{req:knowledge-sources}}
    \end{requirement}

    \begin{requirement}
      It must be possible to configure controllers for the way they
      react to certain states of the system.
      \caption{configuring controllers\label{req:configure-controllers}}
    \end{requirement}

    \begin{requirement}
      It should be possible to reconfigure controllers on runtime.
      \caption{reconfiguring controllers\label{req:reconfigure-controllers}}
    \end{requirement}

    The Blackboard system to be build is going to allow the programmer
    to define a workload structure and a knowledge source that will
    react on such a workload. Finally (s)he will define a partial
    solution structure that results from the work. A controller will
    then recognize such a workload and assign it to a fitting
    knowledge source. It will be notified that a result is produced
    and think of what next step to take.

    Information on what type of knowledge source can take on what kind
    of workload will be stored in a database.

    It is expected that even in operational state the self-calibration
    will be under development. It might also put different demands on
    different observations. For this a library of control-strategies
    will be convenient. On top of that it will necessary to change or
    add control-strategies and low-level algorithms as we go.

    \begin{requirement}
      It would be nice to have a library of strategies that
      would include "conditions" and "actions to
      take".
      \caption{library of strategies\label{req:strategies}}
    \end{requirement}

    The blackboard architectural pattern facilitates this tweaking of
    different algorithms by its loose coupling. The different
    protocols between components in the system need to be very well
    specified for this.

    A knowledge source it's result definition must include an
    interpreter object that can return a quality of the result. For a
    controller it must be clear in what kind of new workload the
    result results.

    As a controller object one would want to assign a workload to an
    knowledge source as soon as the decision that such work is needed
    is made. Overhead caused by waiting for the resource to become
    available or for the process to start and initialize should be
    avoided.

    For fast invocation of calibration engines it might be a good
    idea to have them implemented as servers. This can for instance be
    done by running them as unix-demons on nodes that might be used as
    hosts to the predict/solve knowledge
    sources. \hyperlink{bib:Efficiency}{[HEW98]} describes the
    usefulness of this principle. However it is not to be expected
    that this will greatly enhance the execution speed as suggested in
    this paper, as our knowledge-sources will have longer execution
    times and less invocations.

    For unattended invocation of calibration engines a message queue
    can be created that will contain workloads in order of precedence
    or priority. This can help if the current workload is not
    necissarily the only cause for a new workload for a certain
    engine.

  \section{selfcal use of the blackboard pattern}
  \label{sec:selfcal-use-blackboard}
  \begin{figure}
    \includegraphics[]{../figures/blackboard-use_concept.eps}
    \hypertarget{fig:blackboard-use}{}
    \caption{the way the BlackBoard will be used to monitor several
    solution threads\label{fig:blackboard-use}}
  \end{figure}

    \subsection{pattern components}
    \label{subsec:pattern-components}

      \begin{figure}
        \includegraphics[]{../figures/overview.eps}
        \hypertarget{fig:overview}{}
        \caption{the crude structure of a selfcal-BlackBoard\label{fig:overview}}
      \end{figure}

      In \hyperlink{fig:overview}{figure \ref{fig:overview}} a high
      level design of a blackboard framework is shown. The
      communication from the TreadController or the ThreadWatcher to
      the WorkerProxy in \hyperlink{fig:overview}{Figure
      \ref{fig:overview}} and back is all done by means of the
      BlackBoard.

      The items in the diagram are \begin{itemize}

      \item \em{Blackboard}: Has ownership of all control -data and knowledge of all
      user data. It starts by deploying the needed knowledge sources
      and by forking if the strategy so commands. It is not an active
      object. It reacts to requests from the rest of the world. An
      implementation could be a tcp-server application.

      \item \em{ThreadWatcher}: Has responsibility over a number of
      solution threads. The thread watcher compares states of solution
      threads and decides if one more promising then the other.

      \item \em{ThreadController}: Has responsibility over a single
      solution thread. The thread controller create new lines of work
      and workloads and check if they lead to satisfying result.


      \item \em{WorkerProxy}: Polls for work to do in the
      database.(pull, push is more desirable. Can be done when the
      database supports action paradigm/trigger) It has an abstract
      function, e.g. "perform" that starts applying the real
      knowledge.

      \item \em{SelfcalWrapper}: Triggers the selfcal engine by means of its "perform"
      function. It puts the status of the real knowledge-source on the
      blackboard, when it changes. It also writes back results to the
      blackboard if needed.

      \item \em{selfcal engine}: The actual (external) program that
      can perform a series of calibration steps.

      \end{itemize}

    \subsection{demo design}
    \label{subsec:demo-design}

      \begin{figure}
        \includegraphics[]{../figures/democlasses.eps}
        \hypertarget{fig:democlasses}{}
        \caption{\label{fig:democlasses}}
      \end{figure}

      The actual program structure as used in the breadboard
      implementation of the blackboard is shown in
      \hyperlink{fig:democlasses}{Figure \ref{fig:democlasses}}. This
      structure seems rather complete and though the actual
      implementation is useless in the real-life version, there is no
      reason to change this structure as of yet.

    \subsection{a demo use-case}
    \label{sec:demo-usecase}
      \subsubsection{logical structure}
      \label{subsec:logical-structure}
      \begin{figure}
        \includegraphics[]{../figures/demo.usecase.eps}
        \hypertarget{fig:demo-usecase}{}
        \caption{the basic use-case for the self-calibration
        application\label{fig:demo-usecase}}
      \end{figure}

      The use-case, shown in \hyperlink{fig:demo-usecase}{Figure
      \ref{fig:demo-usecase}} is intended to demonstrate the use of
      the blackboard based architecture for the implementation of the
      selfcal controller.

      It will show that concurrent solution threads as shown in
      \hyperlink{fig:blackboard-use}{Figure
      \ref{fig:blackboard-use}} are feasible to implement.

      The demo starts with the selection of a strategy, which
      currently is hand-/hard-coded in a python script. The strategy
      defines how the total processing job is split in subtasks that
      are controlled through their own BlackBoards. Also the strategy
      defines the subset of parameters that each Thread will solve
      for.

      The strategy chosen for this demo is as follows; The data set
      responsibility is split in two over time. After that the second
      part is split in three over frequency. As there is no real
      dataset involved we only let one BlackBoard control 'real'
      actions. the first child at top level is the lucky one. It
      starts three Thread/Controller instantiations with a quite
      similar set of parameters to solve. Each Thread gets the same
      parameters to work on. They all get responsibility over a
      distinct parameter. Also two of the Threads get a shared
      responsibility over a parameter. An extended demo could involve
      a Watcher that merges parameters at certain points in time. That
      is, the Watcher would feed back the (half-)solved parameters of
      the one Thread to the other.

      Now that the strategy is selected, the calibration can be
      performed.  As defined in our strategy, the calibration is
      controlled by a hierarchy of six BlackBoard instantiations. The
      dataset is split over these BlackBoards, and now the
      responsibility over parameters is split as well.

      Termination strategies can be of the form \[for ( 0 < i < n ) :
      action\] or \[while (\Delta > x): action\] This second
      approach can be dangerous, if the calibration process is not
      strictly convergent. For now the results are classified as good
      enough by the user terminating the program.

      After solving we can decide that our results are good enough. Or
      otherwise we continue solving with a modified selection of
      parameters per thread. This we will have to hard-code in the top
      level strategy. In this way we can demonstrate that we can solve
      for dependent parameters.

      \begin{table}[hbt]
        \begin{center}%
          \hypertarget{parametertable}{}%
          \caption{parameters used, responsibilities and end-results\label{tab:parametertable}}
          \begin{tabular}{|c|c|c|c|c|c|}
            \hline 
            parameter & assigned to 1 & to 2 & to 3 & modelled value & result\tabularnewline
            \hline 
            4.38187736305 & yes & no & no & 4 & 3.35925626755 \tabularnewline
            \hline 
            78.754188756 & no & yes & no & 8 & 8.45443058014 \tabularnewline
            \hline 
            6.27352461391 & no & no & yes & 12 & 12.0457830429 \tabularnewline
            \hline 
            75.4624074405 & yes & yes & no & 16 & 19.0403251648 \tabularnewline
            \hline 
            & & & & & 17.905040741 \tabularnewline
            \hline 
            & & & & & 17.5622787476 \tabularnewline
            \hline 
            50.036219115 & yes & no & yes & 20 & 20.7736625671 \tabularnewline
            \hline
            & & & & & 20.750919342 \tabularnewline
            \hline
            & & & & & 20.4077949524 \tabularnewline
            \hline
            99.2854373037 & no & yes & yes & 24 & 30.6347846985 \tabularnewline
            \hline 
            & & & & & 27.5158157349 \tabularnewline
            \hline
            & & & & & 26.8203983307 \tabularnewline
            \hline
          \end{tabular}
        \end{center}
      \end{table}

      \begin{verse}{Note}

        The responsibility over last three parameters is shared
        between two solution-threads and rotating over the three
        available threads. This is done to get an idea on how
        solution-threads can influence each other.
     
      \end{verse}

      In \hyperlink{tab:parametertable}{Table \ref{tab:parametertable}} the
      column ``model value'' stands for ``value according to global
      sky- or instrument model''

      The predict solve step is simulated by a simple formula that
      puts some inter-dependency in the parameters.

    \subsection{implementation}
    \label{subsec:implementation}

      \subsubsection{demo prerequisites}
      \label{subsubsec:demo-prerequisites}

        For the breadboard implementation the following software
        packages where used:

        \begin{itemize}

          \item python 2.3b1

          \item postgresql 7.3.3

          \item swig-1.3.19\footnote{used at compile-time\label{compile-time}}

          \item gcc-3.3\footnotemark[\value{footnote}]

        \end{itemize}

      \subsubsection{The strategy}
      \label{subsubsec:stategy}
        A high level script

        The implementation of the strategy is a python script using
        the components defined in the selfcal implementation of the
        blackboard framework. In the final (c++-)implementation of
        selfcal this might become a database or hard-coded commands. The high level control object is a process with an
        embedded python interpreter. It reads the script when started
        and in an advanced enterprise-pro-gold version it might supply
        a GUI to interrupt and/or change the strategy on the fly. The
        database used supplies the possibility to watch progress
        on-line and intervene if needed.

      \subsubsection{the solver}
      \label{subsubsec:solver}
        The solver is implemented as a c++ stub with a generated
        python wrapper.

        The code that makes parameters converge is:

\begin{Verbatim}[]
      outparams[i] = itsParamValues[i] =
         0.8*(itsParamValues[i] + i + 1) +
         0.01*(4*((i+1)%itsLen + 1) - itsParamValues[(i+1)%itsLen]) -
         0.005*(4*((i-1)%itsLen + 1) - (itsParamValues[(i-1)%itsLen]));
\end{Verbatim}

        As one can see neighbouring parameters are taken into account to
        emulate interdependencies. The effect that we hope to see is
        that some parameters will converge to wrong values due to
        dependencies on wrongly - or not calibrated parameters. A
        cleaver strategy or a observing operator should then change
        some parameters in order to get the calibration back on
        track. This happens in the second half of our calibration
        script, where solved parameters get distributed from the
        responsible solution-thread to other solution-threads.

        The full code can be found in \hyperlink{stub-code}{Appendix
        {\ref*{app:stub-code}}}

    \subsection{results}
    \label{subsec:results}

      \subsubsection{resulting graphs}
      \label{subsubsec:resulting-graphs}

      \begin{figure}
        \includegraphics[]{../figures/results.eps}
        \hypertarget{fig:results}{}
        \caption{the full set of results evolving through time\label{fig:results}}
      \end{figure}

      In \hyperlink{fig:results}{figure \ref{fig:results}} several parameters
      can be seen that are not being solved for. These are exchanged
      from the engine that does solve for them to the engines that
      don't. for instance the pink and green lines that stay near 78
      are the parameters 2 as engines one and three use them. As the
      solution is found sound they get transferred to these engines
      and used henceforth.

      \paragraph{diverting}

        \begin{figure}
          \includegraphics[]{../figures/param1.eps}
          \hypertarget{fig:param1}{}
          \caption{the results on parameter \#1 for the three engines evolving through time\label{fig:param1}}
        \end{figure}

        In \hyperlink{fig:param1}{figure \ref{fig:param1}} the
        relevant evolutions of parameters having to do with parameter
        \#1 can be seen. The parameters that are stable between 4 and
        5, are being transfered from one engine to another. In this
        case the value is one that has diverted from the right
        solution. Because this is not intended, it shows an important
        pitfall to the approach of distributing responsibility over
        parameters. Even though in this case the end result turns out
        OK. There need to be a tight watch on the quality of results
        to prevent such erroneous behaviour.

        \begin{lessonlearned}
          There need to be a tight watch on the quality of results to
          prevent such erroneous behaviour.
          \caption{watch out for diversions.\label{les:diversion}}
        \end{lessonlearned}

      \paragraph{distribution of responsibilities}

        \begin{figure}
          \includegraphics[]{../figures/1st.eps}
          \hypertarget{fig:1st}{}
          \caption{the results of the first engine evolving through time\label{fig:1st}}
        \end{figure}

        In \hyperlink{fig:1st}{figure \ref{fig:1st}} the solution
        threads of the first engine can be seen. As parameter \#1
        somewhat depends on parameter \#2, and engine 1 uses 78
        instead of 8 to begin with, it's solution is going totally the
        wrong way. As the semi-good solution of about 13 is handed by
        engine \#2, the value of parameter one converges back to the
        expected/right solution of 4. Parameter \#3, however is not of
        in an extreme fashion. Also the dependency of parameter \#4
        and indirectly of parameters \#5 and \#6 are less dramatic.
        This shown that a given a close watch on the quality of
        solutions, the distribution of responsibilities can lead to
        desirable results.

      \paragraph{over-compensation}

        \begin{figure}
          \includegraphics[]{../figures/2nd.eps}
          \hypertarget{fig:2nd}{}
          \caption{the results of the second engine evolving through time\label{fig:2nd}}
        \end{figure}

        \begin{figure}
          \includegraphics[]{../figures/param3.eps}
          \hypertarget{fig:param3}{}%
          \caption{the results on parameter \#3 for the three engines evolving through time\label{fig:param3}}
        \end{figure}

        in \hyperlink{fig:2nd}{figure \ref{fig:2nd}} the same thing
        happens but in this case the value of parameter \#2 drags the
        value of parameter \#3 beyond the value that was
        expected. However as can be seen in
        \hyperlink{fig:param3}{figure \ref{fig:param3}}, things turn
        out all right as soon as a better intermediate result is being
        used.

%%       \paragraph{engine \#3}

%%         \begin{figure}
%%           \includegraphics[]{../figures/3rd.eps}
%%           \hypertarget{fig:3rd}{}%
%%           \caption{the results of the third engine evolving through time\label{fig:3rd}}
%%         \end{figure}

%%      \paragraph{parameter \#3}


    \subsection{evaluation}
    \label{subsec:evaluation}\hypertarget{subsec:evaluation}{}

      Much effort has to put into defining protocols for the
      inter-component communication within the system. Especially
      since part of the components will be pluggable, and their data
      formats unknown to the Blackboard framework. In the breadboard
      implementation these where all known, this might not be in a
      real life version.

      \begin{lessonlearned}
        Protocols will have to be specified very rigidly as they will
        be validated and handled by components that have no knowledge
        of the possible content.
        \caption{protocol definitions\label{les:protocols}}
      \end{lessonlearned}

      The demo application shows us what we wanted to see. It shows
      that distribution of parameters can be monitored. It is a very
      limited example of what might happen of course. Sometimes
      parameters might be described as polynomials over a dimension
      that has been partitioned over. It will have to be a continuous
      function. This might not be possible if the partitions are
      solved for independently.

      A solid way to describe solution strategies is not available
      yet. One will have to be developed.

  \section{lessons learned}
  \label{sec:lessons-learned}

    \subsection{general}

    It seems hard to find an example of an implementation of a
    Blackboard system that compares to this one. The facts, that there
    is only one fundamental knowledge-source, that the amount of data
    is so huge, that several strategies might be explored
    simultaneously, that priority might be added to a strategy, that
    watchers hang around to evaluate intermediate results, have no or
    hardly any prior implementations.

    The metaphor blackboard seems not to the point as the main task of
    the system is to distribute simple and similar tasks as opposed to
    highly specialised ones.

    \subsection{specific}

      \listof{lessonlearned}{}

    \subsection{to do}

      Figure out a priority mechanism.

\newcommand{\dbappendix}[1]{\section{#1}}
\appendix

  \dbappendix{assumptions}
  \label{app:assumptions}\hypertarget{app:assumptions}{}

    \listof{assumption}{}

  \dbappendix{requirements list}
  \label{app:requirements-list}\hypertarget{app:requirements-list}{}

    \listof{requirement}{}

  \dbappendix{strategy}
  \label{app:start-script}\hypertarget{app:start-script}{}

\begin{Verbatim}[]
#!/usr/bin/env python

"""
The blackboard package

$Id$

"""
from bb.BlackBoard import BlackBoard;
from bb.Thread import Thread;
from bb.Controller import Controller;
from bb.Engine import Engine;
from util import paramset;
import util.pglist;

#import bb;


blb = BlackBoard();
blbEarlyChild = None;
blbLateChild = None;

# first get the list of children and the assign them, as can be seen
# at the sublevel this order can be reversed.

topLevelChildren = blb.split_over_time(2);
blbEarlyChild = topLevelChildren[0];
blbLateChild = topLevelChildren[1];

# Adjust the range for the second half of the observation.

blbLateChild.frequency(20,200);

# Initialize the children at the sublevel.

blbLateChildLowChild = None;
blbLateChildMiddleChild = None;
blbLateChildHighChild = None;

# Here we first put the children in the list and then assign them all
# at once. The catch is that you might assign (to) a list with the wrong length.

subLevelChildren = [blbLateChildLowChild, blbLateChildMiddleChild, blbLateChildHighChild];
subLevelChildren = blbLateChild.split_frequency(3);

# Now forget about all of this and work with one of the BlackBoards.
# make a set of assumptions for the parameters. These can be different
# in size for both engines.

numOfParams = 4;

# still fiddling with random in pyton.

paramset.unsetRandom();

ps = util.pglist.list2pgArray(paramset.mkParamSet(numOfParams));

# make the assignments:

ja1 = util.pglist.list2pgArray([True, False, False, False]);
ja2 = util.pglist.list2pgArray([False, True, True, False]);
ja3 = util.pglist.list2pgArray([False, False, True, True]);

# initialize the workloads

wl1 = {};
wl2 = {};
wl3 = {};

wl1["parameterset"] = ps
wl1["jobassignment"] = ja1;
wl1["status"] = "new";

wl2["parameterset"] = ps 
wl2["jobassignment"] = ja2;
wl2["status"] = "new";

wl3["parameterset"] = ps 
wl3["jobassignment"] = ja3;
wl3["status"] = "new";

# create thread (starts)

thr1 = Thread(wl1);
thr2 = Thread(wl2);
thr3 = Thread(wl3);

# create controllers for those threads:

thr1cntrl = Controller(thr1);
thr2cntrl = Controller(thr2);
thr3cntrl = Controller(thr3);

# create the engines to work with:

eng1 = Engine();
eng2 = Engine();
eng3 = Engine();

# assign the engines to the threads:

thr1cntrl.addEngine(eng1);
thr2cntrl.addEngine(eng2);
thr3cntrl.addEngine(eng3);

# register the knowledge sources for (execution)thread control.

blbEarlyChild.register(thr1cntrl);
blbEarlyChild.register(thr2cntrl);
blbEarlyChild.register(thr3cntrl);
blbEarlyChild.register(eng1);
blbEarlyChild.register(eng2);
blbEarlyChild.register(eng3);

# all done start the calibration

blbEarlyChild.start();

# the program may not be ended as this gets to the screen. Then again
# it might.
import time;
time.sleep(10)

print "this is the end"
\end{Verbatim}

  \dbappendix{solver\ stub\ code}
  \label{app:stub-code}\hypertarget{app:stub-code}{}

\begin{Verbatim}[]
//  SelfcalEngineStub.h: one line description
//
//  Copyright (C) 2002
//  ASTRON (Netherlands Foundation for Research in Astronomy)
//  P.O.Box 2, 7990 AA Dwingeloo, The Netherlands, seg@astron.nl
//
//  This program is free software; you can redistribute it and/or modify
//  it under the terms of the GNU General Public License as published by
//  the Free Software Foundation; either version 2 of the License, or
//  (at your option) any later version.
//
//  This program is distributed in the hope that it will be useful,
//  but WITHOUT ANY WARRANTY; without even the implied warranty of
//  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
//  GNU General Public License for more details.
//
//  You should have received a copy of the GNU General Public License
//  along with this program; if not, write to the Free Software
//  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
//
//  $Id$

#include "SelfcalEngineStub.h"

#include <unistd.h>
    //#include <iostream.h>
#include <iostream>
#include <ostream>


SelfcalEngineStub::SelfcalEngineStub():itsParamValues(NULL),debug(false) {
  std::cout << "SelfcalEngineStub Constructor " << std::endl;
}

SelfcalEngineStub::~SelfcalEngineStub() {
  std::cout << "SelfcalEngineStub Destructor " << std::endl;
  if (itsParamValues != NULL) delete[] itsParamValues;
}

void SelfcalEngineStub::init(int len,
			     float parameters[]) {
  if (itsParamValues != NULL) delete[] itsParamValues;
  itsLen = len;

  itsParamValues = new float[len];
  for (int i=0; i<len; i++) {
    itsParamValues[i] = parameters[i];
  }
}

float * SelfcalEngineStub::Solve(bool    *workdef, 
                                  float   outparams[]) {
  if(debug)
    std::cout << "start Solving" << std::flush;
  for (int i=0; i<itsLen; i++) {
    //sleep(1);
    if(debug)
      std::cout << "." << std::flush;

    if (workdef[i] == true) {
      outparams[i] = itsParamValues[i] =
         0.8*(itsParamValues[i] + i + 1) +
         0.01*(4*((i+1)%itsLen + 1) - itsParamValues[(i+1)%itsLen]) -
         0.005*(4*((i-1)%itsLen + 1) - (itsParamValues[(i-1)%itsLen]));
    }
    if(debug)
      std::cout << i << " " << outparams[i] << " " << workdef[i] << "  ";
  }
  if(debug)
    std::cout << "OK" << std::endl;;
  
  return outparams;
  
}


void SelfcalEngineStub::dump() {
  for (int i=0; i<itsLen; i++) {
    std::cout << itsParamValues[i] << " ";
  }
  std::cout << std::endl;
}
\end{Verbatim}

  \dbappendix{revision log}
  \label{app:revisionLog}\hypertarget{app:revisionLog}{}%

    Hand copy log entries from the cvs log, or make up your own.

    \begin{itemize}

      \item 

        Revision 1.1 2003/06/18 12:06:25 daan

        frame and appendix for revision entries

    \end{itemize}

  \bibliography{}
  \begin{thebibliography}{WIDELABEL}

    \bibitem[NII89]{NII}
      \emph{Blackboard Architectures and Applications} ,
      Penny Nii,
      Copyright \copyright{} 1989 Academic Press Inc.,
      B. Chandrasekaran,
      0-12-379940-6,
      Academic Press Inc.,
      xix-xxix.
      \label{bib:nii}

    \bibitem[COR89]{Design-Alternatives}
      \emph{Design Alternatives for Paralel and Distributed Blackboard Systems} ,
      Daniel Corkill.
      \label{bib:Design-Alternatives}

    \bibitem[HEW98]{Efficiency}
      \emph{EFFICIENCY MECHANISMS FOR A CLASS OF BLOACKBOARD SYSTEMS} ,
      Ratikorn Hewett and Micheal Hewett.
      \label{bib:Efficiency}

    \bibitem[SCH02-1]{LOFAR-ASTRON-ADD-006}
      \emph{LOFAR Architectural Design Document} ,
      Kjeld van der Schaaf,
      Copyright \copyright{} 2002 ASTRON.
      \label{bib:LOFAR-ASTRON-ADD-006}

    \bibitem[SCH02-2]{LOFAR-ASTRON-MEM-035}
      \emph{CEP Requirements Analysis, Architectural Design and
      Description} ,
      Kjeld van der Schaaf,
      Copyright \copyright{} 2002 ASTRON.
      \label{bib:LOFAR-ASTRON-MEM-035}

    \bibitem[SCH03]{PDR-CEP-Software}
      \emph{CEP Software implementations} ,
      Kjeld van der Schaaf,
      Copyright \copyright{} 2003 ASTRON.
      \label{bib:PDR-CEP-Software}

  \end{thebibliography}

% --------------------------------------------
% End of document
% --------------------------------------------
\end{document}
